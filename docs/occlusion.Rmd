---
title             : "The role of counterfactual visibility in seeing absence"
shorttitle        : "The role of counterfactual visibility in seeing absence"

author: 
  - name          : "Matan Mazor"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Malet Street, London WC1E 7HX"
    email         : "mtnmzor@gmail.com"
  #   role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
  #     - Conceptualization
  #     - Writing - Original Draft Preparation
  #     - Writing - Review & Editing
  
  - name          : "Clare Press"
    affiliation   : "1,2"
    # role:
    #   - Writing - Review & Editing

affiliation:
  - id            : "1"
    institution   : "Birkbeck, University of London"
  - id            : "2"
    institution   : "Wellcome Centre for Human Neuroimaging, UCL"


abstract: |

  Perceptual decisions are based not only on incoming sensory input, but also on our beliefs regarding the likelihood of input given competing hypotheses about the world. This role of probabilistic reasoning in perception is especially pertinent when deciding that a stimulus is absent, where decisions are based not on the visibility of a stimulus, but on counterfactual visibility: the degree to which a stimulus would have been visible if present. We provide a generalized, normative model of visual detection that accounts for this inferential asymmetry and accurately predicts key behavioural asymmetries in visual detection. To test the effects of beliefs about counterfactual visibility on perceptual decisions, we present data from three pre-registered experiments where participants performed a near-threshold detection task under different levels of partial stimulus occlusion, thereby visibly manipulating the likelihood function going from external world states to internal perceptual states. We observe differential effects of sensory evidence and occlusion on decisions about presence and absence. Our normative model of visual detection accounts for these asymmetries, and further reveals robust individual differences in counterfactual perception, with some participants systematically incorporating counterfactual visibility into perceptual decisions about absence while others systematically do not. We discuss implications for the varied and inferential nature of visual perception more broadly.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "absence, counterfactual reasoning, perception"
wordcount         : "X"

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_word
bibliography: references.bib
---

# Introduction

After checking Taylor Swift's Wikipedia page, we are confident that she hasn't announced her retirement from music. If she had, it would have been mentioned on her page. We also checked Russian cellist Natalia Gutman's page and didn't see any mention of a similar announcement, but we are not so sure she hasn't made one since her Wikipedia page only gets updated irregularly. The absence of evidence on Wikipedia is enough to make a solid inference in the case of Swift but not in the case of Gutman because we know that information about Swift spreads more efficiently on the internet.

More generally, inferences about the negation of a hypothesis ($H$) depend on our belief in the probability that we would observe evidence ($E$) if $H$ were true ($p(E|H)$) [@walton1992nonfallacious; @walton2010arguments; @oaksford2004bayesian]. In other words, we believe that something is not true (for example, that Taylor Swift hasn't announced her retirement from music) when we believe that "if it were true, we would have heard about it by now" [@goldberg2011if].

Here we examine whether people apply a similar reasoning in the domain of visual perception, and specifically in perceptual decisions about the absence of stimuli. Namely, we ask if absence is inferred when 1) a stimulus is not visible, and 2) it is likely that it would have been visible if it were present. If this is the case, detection decisions in the absence of a stimulus, their biases, timing, and confidence, should depend not on the visibility of the absence of stimuli, but on *counterfactual visibility*: beliefs about the visibility of stimuli that are not in fact present.

<!-- Previously reported behavioural asymmetries in the perception of presence and absence provide some indirect support for this inferential asymmetry, where presence is directly perceived but absence is inferred. Decisions about absence are commonly slower, and are given with lower levels of subjective confidence, relative to decisions about presence [@mazor2021stage; @mazor2023paradoxical; @mazor2020distinct]. Furthermore, *metacognitive sensitivity*, that is, the alignment between subjective confidence and objective accuracy, is typically lower in decisions about absence [@kellij2021; @mazor2023paradoxical; @mazor2021stage; @mazor2020distinct; @meuwese2014]. -->

<!-- In what follows, we show that these asymmetries in reaction time and confidence are expected in rational decision makers when the informational value of evidence for presence and absence is itself asymmetrical. Using the same ideal-observer model, we then show that detection decisions in the absence of a stimulus, their biases, timing, and confidence, are critically dependent on *counterfactual visibility* -- implicit beliefs about the visibility of stimuli that are not in fact present -- on perceptual decisions. Finally, we present data from three visual detection experiments, where decisions about presence and absence were taken under different levels of stimulus occlusion. This partial occlusion manipulation allowed us to experimentally dissociate visibility from counterfactual visibility, independently measuring the effects of each on perceptual decisions and confidence in presence and absence. -->

Previous studies provide conflicting evidence with respect to the role of counterfactual visibility in perceptual decisions. Some evidence comes from visual search experiments, where participants immediately recognize the absence of a salient target in cases where a target would have been immediately perceived [@wolfe2021; @mazor2022efficient]. Such flexible adjustment of search-termination times as a function of expected search difficulty may be the signature of a counterfactual reasoning process. For example, when inferring there is no direct target in an array full of blue distractors, an observer may reason "I am not seeing the red target, and a red target would have immediately drawn my attention, therefore, no target is present in this display".

<!-- As a result, detection decisions in the absence of a stimulus, their biases, timing, and confidence, provide a window into the effects of *counterfactual visibility* -- implicit beliefs about the visibility of stimuli that are not in fact present -- on perceptual decisions. -->

Outside visual search, evidence for the incorporation of counterfactual visibility into perceptual decisions is more scarce. In near-threshold detection experiments, participants struggle to adjust their detection criterion (the level of perceptual evidence above which they report stimulus presence) as a function of the expected visibility of stimuli. While it makes sense to interpret faint stimuli as more likely to indicate target presence when expected visibility is low, participants fail to do so when visibility is cued [@gorea2000failure], or manipulated using visual attention [@rahnev2011] or position in the visual field [@solovey2015]. It seems that in these cases, decisions about absence may be based on a fixed, one-size-fits-all perceptual criterion, rather than the invocation of counterfactuals or the adoption of a flexible decision heuristic.

Other theoretical accounts suggest that counterfactual visibility is never needed for perceptual decisions, because the absence of stimuli can be directly perceived in sensory channels. For example, @gold2001 postulate that sensory neurons may have their corresponding "anti-neurons", which fire in response to the absence of a stimulus. Such anti-neurons make it possible for agents to infer stimulus absence not when a stimulus would have been detected, but when stimulus absence is detected by neurons that are sensitive to the physical correlates of absent-ness. Together with the above-mentioned reports of suboptimal placements of the decision criterion, it is unclear whether beliefs about counterfactual visibility ever contribute to perceptual decisions outside visual search, and if they do, in what ways.

In what follows, we first introduce our task, where decisions about presence and absence were taken under different levels of stimulus occlusion. This partial occlusion manipulation allowed us to experimentally dissociate visibility from counterfactual visibility, independently measuring the effects of each on perceptual decisions and confidence in presence and absence. We then contrast two computational accounts for the inferential processes that may underlie behaviour in this task, and in perceptual detection more generally. We show that behavioural patterns in perceptual detection naturally emerge in an ideal observer model when only presence, but not absence, is positively represented in sensory channels. Using the same ideal-observer model, we then show that detection decisions in the absence of a stimulus, their biases, timing, and confidence, are critically dependent on counterfactual visibility: beliefs about the expected visibility of stimuli that are not physically present. Finally, we present data from three visual detection experiments, revealing reliable population heterogeneity in the incorporation of counterfactual visibility into perceptual decisions.  

<!-- Here, we attempted to elucidate the roles of beliefs about counterfactual visibility in perception by having participants perform a visual detection task under different levels of stimulus occlusion. If counterfactual visibility is incorporated into perceptual decisions, but not if detection follows a one-size-fits-all perceptual criterion, occlusion should affect decisions not only when a target is present behind the occluder, but also when there is nothing to occlude. -->

<!-- As expected, partial occlusion had sizable effects on detection when a stimulus was present, robustly degrading perceptual sensitivity, slowing down responses, and bringing down subjective confidence ratings. Occluding absent targets also degraded perceptual specificity and brought down subjective confidence ratings, but had qualitatively different effects on the response times for different participants, reliably slowing down some and speeding up others. This asymmetric pattern is consistent with stimulus absence being inferred, rather than directly perceived, based on counterfactual visibility. -->

```{r setup, include = FALSE}

library('groundhog')
groundhog.library(
  c(
    'papaja',
    'reticulate',
    'tidyverse',
    'broom',
    'cowplot',
    'MESS', # for AUCs
    'lsr', # for effect sizes
    'pwr', # for power calculations
    'brms', # for mixed effects modeling
    'BayesFactor',# for Bayesian t test
    'jsonlite', #parsing data from sort_trial
    'afex', #for anova
    'pracma' # for AUCs
  ), "2023-12-01"
)

library('signcon') # ran remotes::install_github('mufcItay/signcon') on 27/07/2023; commit 4bc947e

r_refs("r-references.bib")
knitr::opts_chunk$set(warning=F,echo=F,message=F,cache=T)

```

# Results

## Task: visual detection under partial occlusion

In three pre-registered online experiments, participants performed a near-threshold detection task in which they made decisions about the presence or absence of a target letter (A or S, in different blocks) in a noisy, dynamic stimulus (Fig. \@ref(fig:design)A). The stimulus remained on the screen, refreshing at 15 frames per second, until a response was made. In Exp. 2, participants rated their confidence on an analog scale after making a decision (Fig. \@ref(fig:design)B). On different trials, random parts of the display were occluded by an overlaid layer of black pixels (Exp. 1) or lines (Exp. 2 and 3; Fig. \@ref(fig:design)C). Participants' task was to "ignore the black stuff, focus on the noise that is under it, and determine whether the letter appeared in it or not". We chose to manipulate stimulus visibility in this way because the effect of occlusion on visibility is relatively obvious: the more occluded objects are, the harder they are to see. This way, occlusion affects not only stimulus visibility, but also beliefs about the counterfactual visibility of stimuli that are not physically present (Fig. \@ref(fig:design)D).

```{r design, echo=FALSE, fig.cap="Rationale and experimental design for Experiments 1-3. A) example frames from target-present (blue) and target-absent (red) trials. B) trial structure in Exp. 2. C) occlusion conditions in the three experiments. In Exp. 1, on different trials we occluded a random subset of 5% or 15% of the pixels in the stimulus. In Exp. 2 and 3, on different trials we occluded a random subset of 2 or 6 pixel rows. In Exp. 3, the task-relevant stimulus was falnked by two reference stimuli that, known to the subject, always had the target letter in them. Participants performed two 32-trial blocks in which the target was the letter S and two blocks in which the target was the letter A. The order of the two letters was randomised between participants. D) occluding more of a target letter decreases its visibility (black markers). Occlusion has no effect on target visibility when the target is absent, but it affects *counterfactual visibility* (white markers): the expected visibility of the target, had it been present.  *The occluder preview screen only appeared in Exp. 2 and 3. **Confidence ratings were given only in Exp. 2, blocks 3 and 4", out.width = '75%'}
knitr::include_graphics("figures/design_occlusion_noisy_stim.png")
```

## An ideal observer model of visual detection

In visual detection tasks, decisions about absence are commonly slower, and are given with lower levels of subjective confidence, relative to decisions about presence [@mazor2021stage; @mazor2023paradoxical; @mazor2020distinct]. Presence-absence asymmetries in reaction time and confidence are expected if evidence is only ever available to support presence, leaving absence to be inferred tentatively and based on the absence of evidence. To formulate this asymmetry in the availability of evidence, we present two variants of a Partially Observed Markov Decision Process [POMDP, @littman2009] model of perceptual detection: a symmetric variant, equipped with a presence-sensor and an absence-sensor (Fig. \@ref(fig:model), left panels) and an asymmetric variant, equipped only with an absence-sensor. Crucially, instead of fitting model parameters to observed behaviour, our motivation is to ask about the conditions under which a given policy would be rational from the point of view of the participant [@anderson1990]. We provide a high-level description of the model here and a more detailed description in the Methods section. As we show, asymmetries in decision time and decision confidence are borne out of rational evidence accumulation when the value of positive and negative evidence is itself asymmetrical.

```{r model, echo=FALSE, fig.cap="Symmetric and asymmetric models of visual detection. A) model architecture. Target presence affects the activation probability of presence and absence sensors. The asymmetric model (right) has no absence sensor. The agent then perceives a series of binary outcomes (sensor activations), based on which it attempts to guess the true world state (target presence or absence). This is done by extracting and accumulating the log likelihood ratio (LLR) for target presence versus absence (interpretation) and deciding whether to make a decision based on available evidence, or alternatively whether to accumulate more evidence. In making this decision, the agent balances the incentive to be as accurate as possible (only correct decisions are associated with a reward) and the exponential discounting of the value of reward as a function of time. B) The first samples from two example trials, one from each model. C) behavioural predictions for an ideal observer. Only the asymmetric model predicts that decisions about absence should be slower, and that they should be accompanied by lower levels of subjective condfidence, than decisions about presence. ", out.width = '75%'}
knitr::include_graphics("figures/compModelGraph.png")
```

We model sensory observations as the binary (on/of) activations of visual sensors which are probabilistically tuned to one state of the world. For example, the "presence sensor" in the symmetric model (\@ref(fig:model)A, left panel) has a $0.05$ activation probability when a target is absent, but this probability goes up to $0.15$ when a target is present. The agent is rewarded for making accurate guesses regarding the state of the world (stimulus presence or absence), given these observations. To increase the probability of being correct, the agent can choose to wait and accumulate more observations before making a decision. However, the subjective value of accuracy rewards is subject to temporal discounting, rendering the value of later correct decisions lower than that of earlier ones.

Given these settings, our agent implements an optimal policy, updating its beliefs about the state of the world by tracking the log likelihood ratio (LLR) between presence and absence given each observation, and committing to a decision only when the expected value of making a decision is higher than the expected value of making a decision later, assuming the same policy will be used in later time points. For our specified setting, the optimal policy is to commit to a "target present" decision once the accumulated LLR hits an upper boundary, commit to a "target absent" decision once the accumulated LLR hits a lower boundary, and continue to accumulate evidence otherwise (see Fig. \@ref(fig:model)B, left panel, for the first time points from an example trial). As an additional measure, we assume that decision confidence equals the probability of being correct at the time of committing to a decision, given the accumulated evidence so far.

The left panels in Fig. \@ref(fig:model) represent a symmetric setting, where two sensors are symmetrically tuned to presence or absence. In this setting, activation of the presence sensor provides evidence for presence and activation of the absence sensor provides similarly informative evidence for absence. Whenever both sensors are inactive, and whenever both sensors activate simultaneously, the belief state stays fixed ($LLR=0$). In this setting, decisions about presence and absence are conceptually symmetrical, resulting in symmetric reaction time and subjective confidence profiles (fig. \@ref(fig:model)C, left panel).

Compare this with the asymmetric model in the right panels of Fig. \@ref(fig:model). This model is identical, except that it lacks an absence sensor (in order to match the decision accuracy of the two models, we also increased the sensitivity of the presence sensor from $0.15$ to $0.20$). This asymmetric model is tasked with a more difficult challenge: now, absence cannot be inferred based on the activation of a sensor. Instead, it needs to be inferred based on periods of inactivation of the presence sensor that are especially unlikely when a target is present. As a result, unlike the symmetric accumulator that is sensitive only to sensor activation, the asymmetric accumulator is pulled toward the lower boundary whenever the present sensor is inactive (Fig. \@ref(fig:model)B, right panel). Still, sensor inactivation is much less informative than sensor activation: activation is $4$ times more likely when a target is present than absent, but inactivation is more likely by a factor of only $1.18$ when a target is absent than present. This asymmetry in the information value of evidence for presence and absence results in slower decisions about absence and lower confidence levels in such decisions, compared to decisions about presence (fig. \@ref(fig:model)C, right panel), in line with the reaction time and confidence profiles of perceptual detection experiments [@kellij2021; @mazor2023paradoxical; @mazor2021stage; @mazor2020distinct; @meuwese2014]. 

### Modeling occlusion effects

We proceed with the asymmetric model, and simulate stimulus occlusion as a scaling of the probability of sensor activation by a parameter $\alpha \in [0,1]$, such that lower levels of $\alpha$ make the sensor less likely to activate. This way, $\alpha$ can be thought of as modulating the visibility of targets (Fig. \@ref(fig:model-occlusion)A). Importantly, in addition to the effects of $\alpha$ on stimulus visibility, beliefs about $\alpha$ also affect how sensory input is interpreted, and how much certainty agents seek before they commit to a decision. Fig. \@ref(fig:model-occlusion)B illustrates the interpretation of the same sensory samples when the agent believes $\alpha$ to be $1$ (corresponding to low occlusion, in black) or $0.7$ (corresponding to high occlusion, in gray). Notably, the information value of sensor inactivation in model B is diminished when $\alpha=0.7$, making the same ambiguous sequence of samples appear more consistent with target presence if the display is known to be occluded. 

In deriving model predictions, we consider two variants of the model (Fig. \@ref(fig:model-occlusion)B). Variant $A$ incorporates into its perceptual decisions fully accurate beliefs about the effect of $\alpha$ on stimulus visibility. This affects both the interpretation stage (when $alpha$ is believed to be low, sensor inactivation, but not sensor activation, becomes less informative) and the action selection stage (by affecting the expected value of future evidence, making the agent more willing to settle for lower decision confidence when occlusion is high). Variant $B$, on the other hand, entirely ignores the expected effects of $\alpha$ on the probability of sensor activation, interpreting evidence in the same average way in both high-occlusion and low-occlusion trials. 
 
```{r model-occlusion, echo=FALSE, fig.cap="Modelling the effects of occlusion on visual detection. A) We model the effect of occlusion as scaling of the probability of sensor activation. B) The first sensory samples from example trials and their corresponding interpretations as a function of the believed visibility level. C) reaction time and confidence effects in simulated rational observers as a function of target presence and absence and level of occlusion, correct trials only. Agent A considers the effect of occlusion when interpreting sensory evidence and making decisions, whereas agent B takes evidence at face value.", out.width = '75%'}
knitr::include_graphics("figures/compModelOcclusionGraphAsym.png")
```


The two agents presented a similar qualitative pattern for decisions in the presence of a target (blue lines in Fig. \@ref(fig:model-occlusion)C): occluding more of the display resulted in a decrease in hit rate, slower correct decisions about presence, and lower levels of subjective confidence in decisions about presence, all consistent with a decrease in the frequencey of sensor activation.

In contrast, the effect of occlusion when a target was absent was qualitatively different for the two agents (red lines in Fig. \@ref(fig:model-occlusion)C). While occluding more of the display made $A$ commit more false-alarms, it made $B$ make fewer of them. $A$'s decisions about absence were slower when more of the display was occluded, whereas $B$'s decisions about absence were *faster*. Finally, $A$ was less confident in decisions about absence when more of the display was occluded, but this was not true of $B$. Unlike its effect on decisions about presence, the effects of occlusion on decisions about absence were entirely mediated by usage of meta-perceptual knowledge about the influence occlusion had on visibility.

```{r load-and-process}
source("../analysis/loadAndPreprocessData.R")
```

```{r load_and_plot_occlusion_simulation, echo=FALSE, cache=TRUE}
detection_colors = c('#377eb8', '#e41a1c');

sim.occlusion <- read_csv('../modelling/simulated_data/accum_bernoulli_occlusion.csv') %>%
  mutate(correct = ifelse(decision==present,1,0))

sim.occlusion_f1 <- read_csv('../modelling/simulated_data/accum_bernoulli_occlusion_fault1.csv') %>%
  mutate(correct = ifelse(decision==present,1,0))

sim.occlusion_sym <- read_csv('../modelling/simulated_data/accum_bernoulli_occlusion_antineuron.csv') %>%
  mutate(correct = ifelse(decision==present,1,0))

sim.occlusion_sym_f1 <- read_csv('../modelling/simulated_data/accum_bernoulli_occlusion_antineuron_fault1.csv') %>%
  mutate(correct = ifelse(decision==present,1,0))

pRT_collapsed <- sim.occlusion %>% 
  filter(correct==1 & occluded_rows==2) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent')))%>%
  group_by(present, occluded_rows)%>%summarise(RT=mean(RT)) %>%
  ggplot(aes(x=present,y=RT,fill=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_shape_manual(values=c(21,22))+
  scale_y_continuous(limits=c(10,22))+
  geom_point(size=3, shape=21) +
  theme_classic() +
  theme(legend.pos='na') +
  labs(y='number of time points',title='Reaction time',x='') 

ggsave('../docs/figures/model/RT_collapsed_square.png',pRT_collapsed, width=2,height=2)


pconfidence_collapsed <- sim.occlusion %>% 
  filter(correct==1 & occluded_rows==2) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent')))%>%
  group_by(present, occluded_rows)%>%summarise(confidence=mean(confidence)) %>%
  ggplot(aes(x=present,y=confidence,fill=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_shape_manual(values=c(21,22))+
  scale_y_continuous(limits=c(0.85,0.95))+
  geom_point(size=3, shape=21) +
  theme_classic() +
  theme(legend.pos='na') +
  labs(y='Bayesian p(correct)',title='Confidence',x='') 

ggsave('../docs/figures/model/confidence_collapsed_square.png',pconfidence_collapsed, width=2,height=2)


detection_colors = c('#377eb8', '#e41a1c');
labels = c('Present','Absent')

conf_discrete_counts <- sim.occlusion %>%
  mutate(confidence = round(confidence*100)/100)%>%
  group_by(decision, correct, confidence, .drop=FALSE) %>%
  tally() %>%
  spread(correct, n, sep='',fill=0) %>%
  arrange(desc(confidence), by_group=TRUE) %>%
  group_by(decision)%>%
  mutate(cs_correct=cumsum(correct1)/sum(correct1),
         cs_incorrect=cumsum(correct0)/sum(correct0))

additional_lines = conf_discrete_counts %>%
  group_by(decision) %>%
  reframe(confidence=c(0,1),cs_incorrect = c(0,1),cs_correct=c(0,1))

conf_discrete_counts = rbind(conf_discrete_counts,additional_lines)

labels=c('present','absent')

p<- ggplot(data=conf_discrete_counts%>%mutate(response=ifelse(decision==1,labels[1],labels[2])%>%factor(levels=labels)),
       aes(x=cs_incorrect, y=cs_correct, color=response)) +
  geom_line(size=1.3) +
  # geom_point(aes(shape = response))+
  geom_abline(slope=1)+
  theme_bw() + coord_fixed() +
  labs(x='p(conf | incorrect)', y='p(conf | correct)')+ 
  scale_color_manual(values=detection_colors)+
  scale_fill_manual(values=detection_colors) +
  scale_x_continuous(breaks=c())+
  scale_y_continuous(breaks=c())+
  geom_rect(aes(xmin=0,xmax=1,ymin=0,ymax=1),size=0.5,color='black',alpha=0)+
  theme_classic()+
  theme(legend.position='none')+
  labs(title='mc sensitivity')

ggsave('../docs/figures/model/AUC_square.png',p,width=2,height=2)

#-------

pRT_collapsed <- sim.occlusion_sym %>% 
  filter(correct==1 & occluded_rows==2) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent')))%>%
  group_by(present, occluded_rows)%>%summarise(RT=mean(RT)) %>%
  ggplot(aes(x=present,y=RT,fill=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_shape_manual(values=c(21,22))+
  scale_y_continuous(limits=c(10,22))+
  geom_point(size=3, shape=21) +
  theme_classic() +
  theme(legend.pos='na') +
  labs(y='number of time points',title='Reaction time',x='') 

ggsave('../docs/figures/model/RT_collapsed_square_sym.png',pRT_collapsed, width=2,height=2)


pconfidence_collapsed <- sim.occlusion_sym %>% 
  filter(correct==1 & occluded_rows==2) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent')))%>%
  group_by(present, occluded_rows)%>%summarise(confidence=mean(confidence)) %>%
  ggplot(aes(x=present,y=confidence,fill=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_shape_manual(values=c(21,22))+
  scale_y_continuous(limits=c(0.85,0.95))+
  geom_point(size=3, shape=21) +
  theme_classic() +
  theme(legend.pos='na') +
  labs(y='Bayesian p(correct)',title='Confidence',x='') 

ggsave('../docs/figures/model/confidence_collapsed_square_sym.png',pconfidence_collapsed, width=2,height=2)


  
detection_colors = c('#377eb8', '#e41a1c');
labels = c('Present','Absent')

conf_discrete_counts <- sim.occlusion_sym %>%
  mutate(confidence = round(confidence*100)/100)%>%
  group_by(decision, correct, confidence, .drop=FALSE) %>%
  tally() %>%
  spread(correct, n, sep='',fill=0) %>%
  arrange(desc(confidence), by_group=TRUE) %>%
  group_by(decision)%>%
  mutate(cs_correct=cumsum(correct1)/sum(correct1),
         cs_incorrect=cumsum(correct0)/sum(correct0))

additional_lines = conf_discrete_counts %>%
  group_by(decision) %>%
  reframe(confidence=c(0,1),cs_incorrect = c(0,1),cs_correct=c(0,1))

conf_discrete_counts = rbind(conf_discrete_counts,additional_lines)

labels=c('present','absent')

p<- ggplot(data=conf_discrete_counts%>%mutate(response=ifelse(decision==1,labels[1],labels[2])%>%factor(levels=labels)),
       aes(x=cs_incorrect, y=cs_correct, color=response)) +
  geom_line(size=1.3) +
  # geom_point(aes(shape = response))+
  geom_abline(slope=1)+
  theme_bw() + coord_fixed() +
  labs(x='p(conf | incorrect)', y='p(conf | correct)')+ 
  scale_color_manual(values=detection_colors)+
  scale_fill_manual(values=detection_colors) +
  scale_x_continuous(breaks=c())+
  scale_y_continuous(breaks=c())+
  geom_rect(aes(xmin=0,xmax=1,ymin=0,ymax=1),size=0.5,color='black',alpha=0)+
  theme_classic()+
  theme(legend.position='none')+
  labs(title='mc sensitivity')

ggsave('../docs/figures/model/AUC_square_sym.png',p,width=2,height=2)

```

```{r plot simulated occlusion effects, echo=FALSE, cache=TRUE}

RT_A<- sim.occlusion %>% 
  filter(correct==1) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(RT=mean(RT)) %>%
  ggplot(aes(x=occluded_rows,y=RT,fill=present, color=present,shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(10,25))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='time points',x='') 

ggsave('../docs/figures/model/RT_A.png',RT_A, width=1.6,height=1.6)

RT_B<- sim.occlusion_f1 %>% 
  filter(correct==1) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(RT=mean(RT)) %>%
  ggplot(aes(x=occluded_rows,y=RT,fill=present, color=present,shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(10,25))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='time points',x='') 

ggsave('../docs/figures/model/RT_B.png',RT_B, width=1.6,height=1.6)

RT_sym_A<- sim.occlusion_sym %>% 
  filter(correct==1) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(RT=mean(RT)) %>%
  ggplot(aes(x=occluded_rows,y=RT,fill=present, color=present,shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(10,25))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='time points',x='') 

ggsave('../docs/figures/model/RT_Asym.png',RT_sym_A, width=1.6,height=1.6)

RT_sym_B<- sim.occlusion_sym_f1 %>% 
  filter(correct==1) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(RT=mean(RT)) %>%
  ggplot(aes(x=occluded_rows,y=RT,fill=present, color=present,shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(10,25))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='time points',x='') 

ggsave('../docs/figures/model/RT_Bsym.png',RT_sym_B, width=1.6,height=1.6)


conf_A<- sim.occlusion %>% 
  filter(correct==1) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(confidence=mean(confidence)) %>%
  ggplot(aes(x=occluded_rows,y=confidence,fill=present, color=present,shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(0.8,1), breaks=seq(0.8,1,0.05))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='Bayes p(correct)',x='') 

ggsave('../docs/figures/model/conf_A.png',conf_A, width=1.6,height=1.6)

conf_B<- sim.occlusion_f1 %>% 
  filter(correct==1) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(confidence=mean(confidence)) %>%
  ggplot(aes(x=occluded_rows,y=confidence,fill=present, color=present,shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(0.8,1), breaks=seq(0.8,1,0.05))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='Bayes p(correct)',x='') 

ggsave('../docs/figures/model/conf_B.png',conf_B, width=1.6,height=1.6)

conf_sym_A<- sim.occlusion_sym %>% 
  filter(correct==1) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(confidence=mean(confidence)) %>%
  ggplot(aes(x=occluded_rows,y=confidence,fill=present, color=present,shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(0.8,1), breaks=seq(0.8,1,0.05))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='Bayes p(correct)',x='') 

ggsave('../docs/figures/model/conf_Asym.png',conf_sym_A, width=1.6,height=1.6)

conf_Bsym<- sim.occlusion_sym_f1 %>% 
  filter(correct==1) %>%
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(confidence=mean(confidence)) %>%
  ggplot(aes(x=occluded_rows,y=confidence,fill=present, color=present,shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(0.8,1), breaks=seq(0.8,1,0.05))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='Bayes p(correct)',x='') 

ggsave('../docs/figures/model/conf_Bsym.png',conf_Bsym, width=1.6,height=1.6)

acc_A<- sim.occlusion %>% 
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(errors=1-mean(correct)) %>%
  ggplot(aes(x=occluded_rows,y=errors,fill=present, color=present, shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(0,0.3), breaks=seq(0,0.35,0.05))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='error rate',x='') 

ggsave('../docs/figures/model/acc_A.png',acc_A, width=1.6,height=1.6)

acc_B<- sim.occlusion_f1 %>% 
  mutate(present=factor(present,levels=c(1,0),labels=c('present','absent'))) %>%
  group_by(present, occluded_rows)%>%summarise(errors=1-mean(correct)) %>%
  ggplot(aes(x=occluded_rows,y=errors,fill=present, color=present, shape=present)) +
  scale_fill_manual(values=detection_colors) +
  scale_color_manual(values=detection_colors) +
  scale_y_continuous(limits=c(0,0.3), breaks=seq(0,0.35,0.05))+
  geom_line()+
  geom_point(size=2) +
  theme_classic() +
  theme(legend.pos='na') +
  scale_x_continuous(limits=c(0,8),breaks=c(2,6),labels=c('easy','hard'))+
  labs(y='error rate',x='') 

ggsave('../docs/figures/model/acc_B.png',acc_B, width=1.6,height=1.6)



```





## Experiment 1: pixel occlusion

`r E1.raw_df$subj_id%>%unique()%>%length()` participants performed a near-threshold detection task, in which they made decisions about the presence or absence of a target letter (A or S, on different blocks) in a noisy, dynamic stimulus (see Fig. \@ref(fig:design)B). On different trials, either 5 or 15 percent of the stimulus pixels were occluded by a static layer of randomly positioned black pixels. Participants' task was to "ignore the black stuff, focus on the noise that is under it, and determine whether the letter appeared in it or not". Based on our [pre-registered exclusion criteria](https://osf.io/e6x82), we excluded `r E1.to_exclude%>%length()` participants, leaving `r E1.df$subj_id%>%unique()%>%length()` for the main analysis.

```{r SDT, echo=FALSE, cache=TRUE}

E1.overall_descriptives<- E1.df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  mutate(resp = response==presence_key)%>%
  group_by(subj_id) %>%
  summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)))

E1.descriptives_by_occlusion<- E1.df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  mutate(resp = response==presence_key)%>%
  group_by(subj_id,hide_proportion) %>%
  summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)))


E1.hit_rate_by_occlusion<- E1.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,hit_rate) %>%
  spread(hide_proportion,hit_rate,sep='')%>%
  mutate(diff=hide_proportion0.05-hide_proportion0.15)

E1.fa_rate_by_occlusion<- E1.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,fa_rate) %>%
  spread(hide_proportion,fa_rate,sep='')%>%
  mutate(diff=hide_proportion0.05-hide_proportion0.15)

E1.d_by_occlusion<- E1.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,d) %>%
  spread(hide_proportion,d,sep='')%>%
  mutate(diff=hide_proportion0.05-hide_proportion0.15)

E1.c_by_occlusion<- E1.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,c) %>%
  spread(hide_proportion,c,sep='')%>%
  mutate(diff=hide_proportion0.05-hide_proportion0.15)

E2.overall_descriptives<- E2.df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  mutate(resp = response==presence_key)%>%
  group_by(subj_id) %>%
  summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)))


E2.descriptives_by_occlusion<- E2.df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  mutate(resp = response==presence_key)%>%
  group_by(subj_id,hide_proportion) %>%
  summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)))


E2.hit_rate_by_occlusion<- E2.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,hit_rate) %>%
  spread(hide_proportion,hit_rate,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35)

E2.fa_rate_by_occlusion<- E2.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,fa_rate) %>%
  spread(hide_proportion,fa_rate,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35)

E2.d_by_occlusion<- E2.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,d) %>%
  spread(hide_proportion,d,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35)

E2.c_by_occlusion<- E2.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,c) %>%
  spread(hide_proportion,c,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35)

E3.overall_descriptives<- E3.df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  mutate(resp = response==presence_key)%>%
  group_by(subj_id) %>%
  summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)))

E3.descriptives_by_occlusion<- E3.df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  mutate(resp = response==presence_key)%>%
  group_by(subj_id,hide_proportion) %>%
  summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)))

E3.hit_rate_by_occlusion<- E3.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,hit_rate) %>%
  spread(hide_proportion,hit_rate,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35)

E3.fa_rate_by_occlusion<- E3.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,fa_rate) %>%
  spread(hide_proportion,fa_rate,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35)

E3.d_by_occlusion<- E3.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,d) %>%
  spread(hide_proportion,d,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35)

E3.c_by_occlusion<- E3.descriptives_by_occlusion %>%
 dplyr::select(subj_id,hide_proportion,c) %>%
  spread(hide_proportion,c,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35)
```

```{r H1, echo=FALSE, cache=TRUE}

E1.RT_by_resp <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  group_by(subj_id,resp) %>%
  summarise(RT=median(RT))%>%
  spread(resp,RT,sep='')%>%
  mutate(diff=respTRUE-respFALSE)

E2.RT_by_resp <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  group_by(subj_id,resp) %>%
  summarise(RT=median(RT))%>%
  spread(resp,RT,sep='')%>%
  mutate(diff=respTRUE-respFALSE)

E3.RT_by_resp <- E3.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  group_by(subj_id,resp) %>%
  summarise(RT=median(RT))%>%
  spread(resp,RT,sep='')%>%
  mutate(diff=respTRUE-respFALSE)
```

```{r H2, echo=FALSE, cache=TRUE}


E1.RT_by_occlusion_in_presence <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.05-hide_proportion0.15);

E1.RT_by_occlusion_in_presence_correct_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & correct) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.05-hide_proportion0.15);

E2.RT_by_occlusion_in_presence <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

E2.RT_by_occlusion_in_presence_correct_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & correct) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

E3.RT_by_occlusion_in_presence <- E3.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000  &resp) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

E3.RT_by_occlusion_in_presence_correct_only <- E3.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000  &resp & correct) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);
```

Mean accuracy in the main experiment was `r E1.overall_descriptives%>%pull(accuracy)%>%mean()` (SD=`r E1.overall_descriptives%>%pull(accuracy)%>%sd()`). Consistent with the response time profile of detection tasks and with the predictions of the asymmetric model (Fig. \@ref(fig:model)), response times were significantly shorter in "target present" compared to "target absent" responses (pre-registered Hypothesis 1: `r printnum(E1.RT_by_resp%>%pull(respTRUE)%>%mean()/1000)` vs `r printnum(E1.RT_by_resp%>%pull(respFALSE)%>%mean()/1000)` seconds; `r apa_print(E1.RT_by_resp%>%pull(diff)%>%t.test())$statistic`). 

As expected, hit rate was reduced by occlusion (`r apa_print(E1.hit_rate_by_occlusion$diff%>%t.test())$statistic`; see Fig. \@ref(fig:main-results)C, blue lines), with a mean hit rate of `r printnum(E1.hit_rate_by_occlusion$hide_proportion0.05%>%mean())` (SD= `r printnum(E1.hit_rate_by_occlusion$hide_proportion0.05%>%sd())`) when 5% of the pixels were occluded, versus `r printnum(E1.hit_rate_by_occlusion$hide_proportion0.15%>%mean())` (SD= `r printnum(E1.hit_rate_by_occlusion$hide_proportion0.15%>%sd())`) when 15% of the pixels were occluded. Unsurprisingly, occluding more of the target made it more difficult to spot. Furthermore, correct target-present decisions were slowed down by pixel occlusion (pre-registered Hypothesis 2: `r printnum(E1.RT_by_occlusion_in_presence_correct_only%>%pull(hide_proportion0.05)%>%mean()/1000)` seconds for 5% occlusion vs `r printnum(E1.RT_by_occlusion_in_presence_correct_only%>%pull(hide_proportion0.15)%>%mean()/1000)` seconds for 15% occlusion; `r apa_print(E1.RT_by_occlusion_in_presence_correct_only%>%pull(diff)%>%t.test())$statistic`; see Fig. \@ref(fig:main-results)B, blue lines). This effect remained significant when incorporating incorrect trials into the analysis (`r printnum(E1.RT_by_occlusion_in_presence%>%pull(hide_proportion0.05)%>%mean()/1000)` vs `r printnum(E1.RT_by_occlusion_in_presence%>%pull(hide_proportion0.15)%>%mean()/1000)` seconds; `r apa_print(E1.RT_by_occlusion_in_presence%>%pull(diff)%>%t.test())$statistic`). Unsurprisingly, occluding more of the target made it more difficult to spot.

```{r H3, echo=FALSE, cache=TRUE}
E1.RT_by_occlusion_in_absence <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.05-hide_proportion0.15);

E1.RT_by_occlusion_in_absence_correct_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp & correct) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.05-hide_proportion0.15);

E2.RT_by_occlusion_in_absence <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

E2.RT_by_occlusion_in_absence_correct_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp & correct) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

E3.RT_by_occlusion_in_absence <- E3.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000  &!resp) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

E3.RT_by_occlusion_in_absence_correct_only <- E3.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000  &!resp & correct) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(RT=median(RT))%>%
  spread(hide_proportion,RT,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);
```

```{r H4, echo=FALSE, cache=TRUE}

E1.RT_by_occlusion_and_response <- merge(
  E1.RT_by_occlusion_in_presence,
  E1.RT_by_occlusion_in_absence,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E1.RT_by_occlusion_and_response_correct_only <- merge(
  E1.RT_by_occlusion_in_presence_correct_only,
  E1.RT_by_occlusion_in_absence_correct_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E2.RT_by_occlusion_and_response <- merge(
  E2.RT_by_occlusion_in_presence,
  E2.RT_by_occlusion_in_absence,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E2.RT_by_occlusion_and_response_correct_only <- merge(
  E2.RT_by_occlusion_in_presence_correct_only,
  E2.RT_by_occlusion_in_absence_correct_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E3.RT_by_occlusion_and_response <- merge(
  E3.RT_by_occlusion_in_presence,
  E3.RT_by_occlusion_in_absence,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E3.RT_by_occlusion_and_response_correct_only <- merge(
  E3.RT_by_occlusion_in_presence_correct_only,
  E3.RT_by_occlusion_in_absence_correct_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);
```

Having established that occlusion affected stimulus visibility, making responses both slower and less accurate when a target was present, we next examined the effects of occlusion on detection responses in the absence of a target. If participants were, like agent $A$, effectively incorporating counterfactual visibility into their criterion placement, we would expect to see an increase in the proportion of false alarms (the proportion of incorrect target-present reports out of all target-absent trials) when more of the target was occluded. If, however, they took evidence at face value like agent $B$, occlusion should be expected to reduce the false alarm rate. In contrast with the predictions of both model variants, false-alarm rate was unaffected by occlusion (`r apa_print(E1.fa_rate_by_occlusion$diff%>%t.test())$statistic`; see Fig. \@ref(fig:main-results)C, red lines), with a mean false-alarm rate of `r printnum(E1.fa_rate_by_occlusion$hide_proportion0.05%>%mean())` (SD= `r printnum(E1.fa_rate_by_occlusion$hide_proportion0.05%>%sd())`) when 5% of the pixels were occluded, versus `r printnum(E1.fa_rate_by_occlusion$hide_proportion0.15%>%mean())` (SD= `r printnum(E1.hit_rate_by_occlusion$hide_proportion0.15%>%sd())`) when 15% of the pixels were occluded.


<!-- This is due to the fact that $p(absence|visibility)$ is a function not only of $p(evidence|absence)$, a quantity that is hardly affected by occlusion (evidence for the presence of a target is expected to be low when a target is absent, regardless of how much of the stimulus is occluded), but also of $p(evidence|presence)$, which *is* affected by occlusion (little evidence is more consistent with target presence when more of the stimulus is occluded; see Fig. \@ref(fig:design)A).  -->


Furthermore, and in contrast to decisions about presence, the timing of decisions about absence was unaffected by the occlusion manipulation (pre-registered Hypothesis 3: `r printnum(E1.RT_by_occlusion_in_absence_correct_only%>%pull(hide_proportion0.05)%>%mean()/1000)` seconds for 5% occlusion vs `r printnum(E1.RT_by_occlusion_in_absence_correct_only%>%pull(hide_proportion0.15)%>%mean()/1000)` seconds for 15% occlusion; `r apa_print(E1.RT_by_occlusion_in_absence_correct_only%>%pull(diff)%>%t.test())$statistic`; see Fig. \@ref(fig:main-results)B, red lines). The effect of occlusion on response time was stronger in decisions about target presence compared to decisions about target absence (pre-registered Hypothesis 4: `r apa_print(E1.RT_by_occlusion_and_response_correct_only%>%pull(interaction)%>%t.test())$statistic`), also when incorporating incorrect responses into the anlaysis (`r apa_print(E1.RT_by_occlusion_and_response%>%pull(interaction)%>%t.test())$statistic`).

(ref:main-results) Main results from Experiments 1-3. A) example screens from the three experiments. B) mean subject-wise estimate of the 50%, 75%, 90% and 95% RT quantiles, as a function of occlusion and target presence. Correct responses only. Error bars represent the standard error of occlusion effects, controlling for inter-subject variability in overall response times. C) hit (blue) and false-alarm rates (red) as a function of occlusion for the three experiments. Error bars represent the standard error of occlusion effects. D) confidence ratings as a function of occlusion and target presence in Exp. 2. Box edges and central lines represent the 25, 50, and 75 quantiles. Whiskers cover data points within four inter-quartile ranges around the median. \*: p\<0.05, \*\*: p\<0.01, \*\*\*: p\<0.001

```{r main-results, echo=FALSE, fig.cap="(ref:main-results)"}
knitr::include_graphics("figures/occlusionResults.png")
```

Finally, and as expected from the asymmetric effects of occlusion on hit-rate and false-alarms, signal detection sensitivity was significantly reduced by occlusion (pre-registered Hypothesis 5: `r apa_print(E1.descriptives_by_occlusion %>%select(subj_id,hide_proportion,d)%>%spread(hide_proportion,d,sep='')%>%mutate(diff=hide_proportion0.05-hide_proportion0.15)%>%pull(diff)%>%t.test)$statistic`), and so was the signal detection criterion $c$ (pre-registered Hypothesis 6: `r apa_print(E1.descriptives_by_occlusion %>%select(subj_id,hide_proportion,c)%>%spread(hide_proportion,c,sep='')%>%mutate(diff=hide_proportion0.05-hide_proportion0.15)%>%pull(diff)%>%t.test)$statistic`). Together, revealing more of the stimulus rendered participants both more likely and faster to detect a letter when it was there, but it did not make them more likely, or faster, to notice its absence when it was missing.

## Experiment 2: row occlusion

In Experiment 1, we found that occlusion affected detection decisions only when a target was present: a finding that was not predicted by model $A$ that made use of counterfactual visibility or by model $B$ that completely ignored it. Importantly, in order to incorporate counterfactual visibility into their perception and inference, participants had to distinguish between not seeing the target due to its absence and due to its occlusion. While occluders in Exp. 1 were marked by a different color (black), and by their fixed position relative to the dynamic stimulus, it is possible that some participants failed to factor the display into a noisy stimulus behind an array of occluders, and instead perceived them as one stimulus.

In Exp. 2, we made the occluders more clearly separate by displaying them on the screen first, with the stimulus appearing behind them after 500 ms. Occluding entire rows instead of single pixels further allowed us to extend the occluders to both sides of the stimulus, making the separation from the main stimulus even clearer (see Fig. \@ref(fig:design)C). `r E2.raw_df$subj_id%>%unique()%>%length()` participants were recruited for Exp. 2. Based on our [pre-registered exclusion criteria](https://osf.io/5yr9e), we excluded `r E2.to_exclude%>%length()` participants, leaving `r E2.df$subj_id%>%unique()%>%length()` for the main analysis.

Mean accuracy in the main experiment was `r E2.overall_descriptives%>%pull(accuracy)%>%mean()%>%printnum()` (SD=`r E2.overall_descriptives%>%pull(accuracy)%>%sd()%>%printnum()`). As in Exp. 1, response times were significantly shorter in decisions about presence compared to absence (pre-registered hypothesis 1: `r printnum(E2.RT_by_resp%>%pull(respTRUE)%>%mean()/1000)` vs `r printnum(E2.RT_by_resp%>%pull(respFALSE)%>%mean()/1000)` seconds; `r apa_print(E2.RT_by_resp%>%pull(diff)%>%t.test())$statistic`). Here too, occlusion had the expected negative effects on hit rate (`r printnum(E2.hit_rate_by_occlusion$hide_proportion0.1%>%mean())` versus `r printnum(E2.hit_rate_by_occlusion$hide_proportion0.35%>%mean())` for 2 or 6 occluded rows, respectively; `r apa_print(E2.hit_rate_by_occlusion$diff%>%t.test())$statistic`) and the expected slowing down of accurate target-present responses (pre-registered hypothesis 2: `r printnum(E2.RT_by_occlusion_in_presence_correct_only$hide_proportion0.1%>%mean()/1000)` vs `r printnum(E2.RT_by_occlusion_in_presence_correct_only$hide_proportion0.35%>%mean()/1000)` seconds for 2 or 6 occluded rows; `r apa_print(E2.RT_by_occlusion_in_presence_correct_only%>%pull(diff)%>%t.test())$statistic`).

We next asked whether a clearer separation between the stimulus and the occluders facilitated incorporation of counterfactual visibility into decisions in the absence of a target. Contrary to Exp. 1, and in line with the predictions for agent $A$, in Exp. 2 an effect of occlusion on false-alarm rate did reach statistical significance (`r printnum(E2.fa_rate_by_occlusion$hide_proportion0.1%>%mean())` versus `r printnum(E2.fa_rate_by_occlusion$hide_proportion0.35%>%mean())` for 2 or 6 occluded rows, respectively; `r apa_print(E2.fa_rate_by_occlusion$diff%>%t.test())$statistic`): participants were more likely to accept they might have missed the target when more of the stimulus was occluded. In contrast, and in agreement with Exp. 1, here too the timing of decisions about target absence was unaffected by the occlusion manipulation (pre-registered hypothesis 3: `r printnum(E2.RT_by_occlusion_in_absence_correct_only$hide_proportion0.1%>%mean()/1000)` vs `r printnum(E2.RT_by_occlusion_in_absence_correct_only$hide_proportion0.35%>%mean()/1000)` seconds for 2 or 6 occluded rows; `r apa_print(E2.RT_by_occlusion_in_absence_correct_only%>%pull(diff)%>%t.test())$statistic`). The effect of occlusion on response times was significantly stronger in target-present compared to target-absent responses (pre-registered Hypothesis 4: `r apa_print(E2.RT_by_occlusion_and_response_correct_only%>%pull(interaction)%>%t.test())$statistic`), also when incorporating incorrect responses into the analysis (`r apa_print(E2.RT_by_occlusion_and_response%>%pull(interaction)%>%t.test())$statistic`).

As in Exp. 1, signal detection sensitivity was significantly reduced by occlusion (pre-registered Hypothesis 5: `r apa_print(E2.descriptives_by_occlusion %>%select(subj_id,hide_proportion,d)%>%spread(hide_proportion,d,sep='')%>%mutate(diff=hide_proportion0.1-hide_proportion0.35)%>%pull(diff)%>%t.test)$statistic`), and so was the signal detection criterion $c$ (pre-registered Hypothesis 6: `r apa_print(E2.descriptives_by_occlusion %>%select(subj_id,hide_proportion,c)%>%spread(hide_proportion,c,sep='')%>%mutate(diff=hide_proportion0.1-hide_proportion0.35)%>%pull(diff)%>%t.test)$statistic`)

```{r H7, echo=FALSE, cache=TRUE}

E2.confidence_by_resp <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2')) %>%
  group_by(subj_id,resp) %>%
  summarise(confidence=mean(confidence, na.rm=T))%>%
  spread(resp,confidence,sep='')%>%
  mutate(diff=respTRUE-respFALSE)

E2.confidence_by_resp_correct_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & correct) %>%
  group_by(subj_id,resp) %>%
  summarise(confidence=mean(confidence, na.rm=T))%>%
  spread(resp,confidence,sep='')%>%
  mutate(diff=respTRUE-respFALSE)
```

```{r H8, echo=FALSE, cache=TRUE}

E2.confidence_by_occlusion_in_presence <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000 & resp) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(confidence=mean(confidence, na.rm=T))%>%
  spread(hide_proportion,confidence,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

E2.confidence_by_occlusion_in_presence_correct_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000 & resp & correct) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(confidence=mean(confidence, na.rm=T))%>%
  spread(hide_proportion,confidence,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

```

```{r H9, echo=FALSE, cache=TRUE}

E2.confidence_by_occlusion_in_absence <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000 & !resp) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(confidence=mean(confidence, na.rm=T))%>%
  spread(hide_proportion,confidence,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

E2.confidence_by_occlusion_in_absence_correct_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000  &!resp & correct) %>%
  group_by(subj_id,hide_proportion) %>%
  summarise(confidence=mean(confidence, na.rm=T))%>%
  spread(hide_proportion,confidence,sep='')%>%
  mutate(diff=hide_proportion0.1-hide_proportion0.35);

```

```{r H10, echo=FALSE, cache=TRUE}

E2.confidence_by_occlusion_and_response <- merge(
  E2.confidence_by_occlusion_in_presence,
  E2.confidence_by_occlusion_in_absence,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E2.confidence_by_occlusion_and_response_correct_only <- merge(
  E2.confidence_by_occlusion_in_presence_correct_only,
  E2.confidence_by_occlusion_in_absence_correct_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);
```

```{metacognitive asymmetry}

E2.unfiltered_df <- E2.df %>%
  filter(!is.na(confidence))%>%
  group_by(subj_id) %>%
    mutate(
      conf_discrete = ntile(confidence,20) %>%
        factor(levels=1:21),
      correct = factor(correct, levels=c(0,1)),
      conf_bi = ifelse(
        resp==1, 
        as.numeric(confidence),
        -1*as.numeric(confidence)),
      )

E2.not_enough_errors <- E2.unfiltered_df %>%
  group_by(subj_id, resp, correct,.drop=FALSE) %>%
  tally() %>%
  group_by(subj_id) %>%
  summarise(enough_errors=min(n)>1) %>%
  filter(!enough_errors)%>%
  pull(subj_id)
  
E2.no_variance <- E2.unfiltered_df %>%
  group_by(subj_id, resp) %>%
  summarise(varconf=var(confidence))%>%
  group_by(subj_id)%>%
  summarise(no_var=min(varconf)==0)%>%
  filter(no_var)%>%
  pull(subj_id)

E2.df <- E2.unfiltered_df %>%
  group_by(subj_id) %>%
  filter(mean(as.numeric(correct))>0.6)%>%
  filter(!(subj_id %in% not_enough_errors) &
           !(subj_id %in% no_variance))

  
E2.disc_subj_stats <- E2.df %>%
    group_by(subj_id) %>%
    summarise(
      bias = mean(ifelse(resp==1,1,0)),
      acc = mean(ifelse(correct==1,1,0)),
      hit_rate = sum(correct==1 & present==1)/sum(present==1),
      false_alarm_rate=sum(correct==0 & present==0)/sum(present==0),
      dprime=qnorm(hit_rate)-qnorm(false_alarm_rate),
      criterion=-0.5*(qnorm(hit_rate)+qnorm(false_alarm_rate)),
      conf=mean(confidence),
      n1 = sum(present==1),
      n2 = sum(present==0))


E2.raw_conf_counts <- E2.df %>%
  mutate(subj_id=factor(subj_id)) %>%
  group_by(subj_id, resp, correct, confidence, .drop=FALSE) %>%
  tally() %>%
  spread(correct, n, sep='', fill=0) %>%
  arrange(desc(confidence), by_group=TRUE) %>%  
  group_by(subj_id, resp)%>%
  mutate(cs_correct=cumsum(correct1)/sum(correct1),
         cs_incorrect=cumsum(correct0)/sum(correct0))
  
E2.conf_counts <- E2.raw_conf_counts %>%
  group_by(subj_id, resp,.drop=TRUE) %>%
  reframe(
    cs_correct=c(0,1),
    cs_incorrect=c(0,1)) %>%
  bind_rows(E2.conf_counts,.) %>% ## add type-2 ROC edges
  group_by(subj_id, resp, cs_incorrect) %>%
  summarise(cs_correct=max(cs_correct)) %>% 
  merge(disc_subj_stats%>%dplyr::select(subj_id,dprime, hit_rate, false_alarm_rate))%>%
  mutate(miss_rate=1-hit_rate,
         cr_rate=1-false_alarm_rate,
         cs_correct_from_sdt= ifelse(resp==1,
           pnorm(qnorm(false_alarm_rate*cs_incorrect), mean=-dprime)/hit_rate,
           pnorm(qnorm(miss_rate*cs_incorrect), mean=-dprime)/cr_rate));

E2.AUC <- E2.conf_counts %>%
    group_by(subj_id, resp,.drop=TRUE) %>%
    summarise(AUC = trapz(cs_incorrect, cs_correct)) %>%
    spread(resp, AUC, sep='')%>%
    mutate(metacognitive_asymmetry=(respTRUE-respFALSE),
           average_AUC=respTRUE/2+respFALSE/2)
  
E2.sdtAUC <- E2.conf_counts %>%
    group_by(subj_id, resp,.drop=TRUE) %>%
    filter(sum(!is.na(cs_correct_from_sdt))>2)%>%
    summarise(AUC = trapz(cs_incorrect, cs_correct_from_sdt)) %>%
    spread(resp, AUC, sep='')%>%
    mutate(metacognitive_asymmetry_from_sdt=(respTRUE-respFALSE))

E2.AUC_control <- E2.AUC %>%
    merge(E2.sdtAUC%>%dplyr::select(subj_id,metacognitive_asymmetry_from_sdt)) %>%
            mutate(metacognitive_asymmetry_control = metacognitive_asymmetry-metacognitive_asymmetry_from_sdt)
```

Finally, in order to measure metacognitive insight into the effects of occlusion on perception, participants reported their subjective level of confidence in their perceptual decisions in blocks 3 and 4 of the task. Consistent with the confidence profile of detection tasks [@mazor2021inference; @mazor2022efficient; @mazor2023paradoxical] and with the predictions of the asymmetric model, confidence was higher in decisions about presence compared to absence (pre-registered hypothesis 7: `r apa_print(E2.confidence_by_resp_correct_only%>%pull(diff)%>%t.test())$statistic`). As expected, confidence in presence was lower when more of the display was occluded (pre-registered hypothesis 8: `r printnum(E2.confidence_by_occlusion_in_presence_correct_only$hide_proportion0.35%>%mean())` vs. `r printnum(E2.confidence_by_occlusion_in_presence_correct_only$hide_proportion0.1%>%mean())` on a 0-1 scale; `r apa_print(E2.confidence_by_occlusion_in_presence_correct_only$diff%>%t.test())$statistic`). Critically, the same was true of confidence in absence (pre-registered hypothesis 9: `r printnum(E2.confidence_by_occlusion_in_absence_correct_only$hide_proportion0.35%>%mean())` vs. `r printnum(E2.confidence_by_occlusion_in_absence_correct_only$hide_proportion0.1%>%mean())`; `r apa_print(E2.confidence_by_occlusion_in_absence_correct_only$diff%>%t.test())$statistic`), with no significant interaction between occlusion and target presence on confidence (pre-registered hypothesis 10: `r apa_print(E2.confidence_by_occlusion_and_response_correct_only%>%pull(interaction)%>%t.test())$statistic`; see Fig. \@ref(fig:main-results)D). Together, unlike reaction times, which were solely affected by visibility, subjective confidence ratings were affected by both visibility and beliefs about the effects of occlusion on visibility: participants were less confident in the absence of a target when it would have been harder to see.

## Experiment 3: providing visual access to the counterfactual

Unlike Exp. 1, in Exp. 2 counterfactual visibility did have an effect on perceptual decisions: participants were more likely to guess that a stimulus was present when they thought they might have missed it, resulting in an increase in the false-alarm rate in high occlusion trials (see Fig. \@ref(fig:main-results)C, middle panel). However, similar to Exp. 1, only visibility, but not counterfactual visibility, had an effect on response times. This absence of an effect of occlusion on response times is surprising: in principle, participants could use their time more efficiently by waiting for longer before inferring absence when detecting the target would have taken longer (high occlusion trials), and quitting earlier when detecting the target would have been more immediate (low occlusion trials). One explanation for this suboptimality could be that subjects fail to mentally simulate the effect of the occlusion manipulation on the speed with which a hypothetical target would have been perceived. To test this, we made this effect immediately available to participants, by presenting two reference stimuli alongside the main stimulus. These stimuli were occluded by the same line occluders, but, known to participants, they always had the target letter in them (see Fig. \@ref(fig:design)D, right panel). Besides the addition of these reference stimuli, the task in Exp. 3 remained the same: decide whether the central stimulus includes the target letter, or not.

`r E3.raw_df$subj_id%>%unique()%>%length()` participants were recruited for Exp. 3. Based on our [pre-registered exclusion criteria](https://osf.io/mfd2w), we excluded `r E3.to_exclude%>%length()` participants, leaving `r E3.df$subj_id%>%unique()%>%length()` for the main analysis.

Mean accuracy in the main experiment was `r E3.overall_descriptives%>%pull(accuracy)%>%mean()%>%printnum()` (SD=`r E3.overall_descriptives%>%pull(accuracy)%>%sd()%>%printnum()`). As in Exp. 1 and 2, response times were significantly shorter in decisions about presence compared to absence (pre-registered hypothesis 1: `r printnum(E3.RT_by_resp%>%pull(respTRUE)%>%mean()/1000)` vs `r printnum(E3.RT_by_resp%>%pull(respFALSE)%>%mean()/1000)` seconds; `r apa_print(E3.RT_by_resp%>%pull(diff)%>%t.test())$statistic`). Occlusion had the expected negative effects on hit rate (`r printnum(E3.hit_rate_by_occlusion$hide_proportion0.1%>%mean())` versus `r printnum(E3.hit_rate_by_occlusion$hide_proportion0.35%>%mean())` for 2 or 6 occluded rows, respectively; `r apa_print(E3.hit_rate_by_occlusion$diff%>%t.test())$statistic`) and the expected slowing down of accurate target-present responses (pre-registered hypothesis 2: `r printnum(E3.RT_by_occlusion_in_presence_correct_only$hide_proportion0.1%>%mean()/1000)` vs `r printnum(E3.RT_by_occlusion_in_presence_correct_only$hide_proportion0.35%>%mean()/1000)` seconds for 2 or 6 occluded rows; `r apa_print(E3.RT_by_occlusion_in_presence_correct_only%>%pull(diff)%>%t.test())$statistic`).

Turning to target-absent trials, we measured the effect of the occlusion manipulation on false-alarms. Similar to Exp. 2, participants committed more false alarms when more of the stimulus was occluded (`r printnum(E3.fa_rate_by_occlusion$hide_proportion0.1%>%mean())` versus `r printnum(E3.fa_rate_by_occlusion$hide_proportion0.35%>%mean())` for 2 or 6 occluded rows, respectively; `r apa_print(E3.fa_rate_by_occlusion$diff%>%t.test())$statistic`). However, and in and agreement with Exp. 1 and 2, the timing of decisions about target absence remained unaffected by the occlusion manipulation (pre-registered hypothesis 3: `r printnum(E3.RT_by_occlusion_in_absence_correct_only$hide_proportion0.1%>%mean()/1000)` vs `r printnum(E3.RT_by_occlusion_in_absence_correct_only$hide_proportion0.35%>%mean()/1000)` seconds for 2 or 6 occluded rows; `r apa_print(E3.RT_by_occlusion_in_absence_correct_only%>%pull(diff)%>%t.test())$statistic`). The effect of occlusion on response times was significantly stronger in target-present compared to target-absent responses (pre-registered Hypothesis 4: `r apa_print(E3.RT_by_occlusion_and_response_correct_only%>%pull(interaction)%>%t.test())$statistic`), also when incorporating incorrect responses into the anlaysis (`r apa_print(E3.RT_by_occlusion_and_response%>%pull(interaction)%>%t.test())$statistic`).

As in Exp. 1, signal detection sensitivity was significantly reduced by occlusion (pre-registered Hypothesis 5: `r apa_print(E3.descriptives_by_occlusion %>%select(subj_id,hide_proportion,d)%>%spread(hide_proportion,d,sep='')%>%mutate(diff=hide_proportion0.1-hide_proportion0.35)%>%pull(diff)%>%t.test)$statistic`), and so was the signal detection criterion $c$ (pre-registered Hypothesis 6: `r apa_print(E3.descriptives_by_occlusion %>%select(subj_id,hide_proportion,c)%>%spread(hide_proportion,c,sep='')%>%mutate(diff=hide_proportion0.1-hide_proportion0.35)%>%pull(diff)%>%t.test)$statistic`)

## Exploratory data analysis: reverse correlation

In all three experiments, we found the timing of decisions about absence to be unaffected by occlusion. This made us wonder whether the timing of decisions about absence is sensitive to any aspect of the stimulus at all. For example, if decisions about absence are made once a noisy timer goes off and before sufficient evidence has been accumulated for presence [a similar model was proposed for decisions about absence in visual search, @wolfe2021, @chun1996], we should expect the timing of decisions about absence to be fully independent of the presented stimulus. If, on the other hand, participants adjust their decision times based on fluctuations in stimulus intensity that are below their decision threshold, decisions about absence should be slower when more evidence is available for presence. To answer this question, we ran a reverse correlation analysis.

Since luminance values were randomly sampled per pixel and frame, the perceived similarity between the presented stimulus and the target letter fluctuated both within and between trials. This allowed us to directly measure how stimulus-target similarity (quantified as the Pearson correlation between unoccluded pixels and their corresponding pixels in the target letter, statistically controlling for the proportion of pure-noise and hidden pixels in the frame) contributed to reaction times in decisions about presence and absence. Following previous reverse correlation studies of decision confidence [@zylberberg2012; @mazor2023paradoxical], we focused our analysis on the first 300 ms of the stimulus presentation, and extracted, per trial, the mean similarity between the display and the target letter in these first frames. We then computed the Spearman correlation between these trial-wise similarity measures and the reaction times, focusing our analysis on correct responses only (see Fig. \@ref(fig:RC)).

```{r rc-confidence, message=F, warning=F, echo=F, include=F}

detection_colors = c('#377eb8', '#e41a1c');

E2.frames_df <- read_csv('../experiments/Exp2rows/data/jatos_resultfiles_batch1/all_data.csv') %>%
  mutate(subj_id=PROLIFIC_PID,
         correct = as.numeric(correct),
         RT = as.numeric(RT),
         present=as.numeric(present),
         resp = response==presence_key)  %>%
  filter(test_part %in% c('test1','test2'))%>%
  mutate(p=ifelse(present==0,0,max_p))%>%
  group_by(p, hide_proportion)%>%
  mutate(correlation_with_target_letter_corrected = 
           correlation_with_target_letter-mean(correlation_with_target_letter, na.rm=T),
         occlusion=factor(ifelse(hide_proportion<0.2,'low','high')))

E2.rc_confidence <- E2.frames_df %>%
  filter(frame_index>7 & frame_index<13 & correct & !is.na(confidence))%>%
  group_by(subj_id,trial_index,present,occlusion)%>%
  summarise(evidence=mean(correlation_with_target_letter_corrected),
            confidence=mean(confidence))%>%
  group_by(subj_id,present,occlusion) %>%
  summarise(confidence=cor(evidence,confidence,method='spearman')) %>%
  group_by(subj_id,present)%>%
  summarise(confidence=mean(confidence))%>%
  spread(present,confidence,sep='') %>%
  mutate(diff=present1+present0)

E2.frames_df %>%
  filter(frame_index>7 & frame_index<40 & correct & !is.na(confidence))%>%
  group_by(subj_id,present,occlusion,frame_index) %>%
  summarise(confidence=cor(correlation_with_target_letter_corrected,confidence,method='spearman')) %>%
  group_by(subj_id,present,frame_index)%>%
  summarise(confidence=mean(confidence))%>%
  group_by(present,frame_index)%>%
  summarise(se=se(confidence),
            confidence=mean(confidence, na.rm=T))%>%
  ggplot(aes(x=frame_index,y=confidence,color=factor(present),fill=factor(present)))+
  geom_abline(slope=0,intercept=0)+
  geom_line()+
  geom_ribbon(aes(ymin=confidence-se,ymax=confidence+se),alpha=0.3)+
      scale_color_manual(values=detection_colors)+
    scale_fill_manual(values=detection_colors)
  
```

```{r rc-RT, message=F, warning=F, echo=F, include=F}

E1.frames_df <- read_csv('../experiments/Exp1pixels/version2/data/jatos_resultfiles_batch1/all_data.csv') %>%
  mutate(subj_id=PROLIFIC_PID,
         correct = as.numeric(correct),
         RT = as.numeric(RT),
         present=as.numeric(present),
         resp = response==presence_key,
         correlation_with_mask=as.numeric(correlation_with_mask)) %>%
  filter(test_part %in% c('test1','test2'))%>%
  mutate(p=ifelse(present==0,0,max_p))%>%
  group_by(p, hide_proportion)%>%
  mutate(correlation_with_target_letter_corrected = 
           correlation_with_target_letter-mean(correlation_with_target_letter, na.rm=T),
         occlusion=factor(ifelse(hide_proportion<0.10,'low','high')))

E3.frames_df <- read_csv('../experiments/Exp3reference/data/jatos_results_files_batch1/all_data.csv') %>%
  mutate(subj_id=PROLIFIC_PID,
         correct = as.numeric(correct),
         RT = as.numeric(RT),
         present=as.numeric(present),
         resp = response==presence_key) %>%
  filter(test_part %in% c('test1','test2'))%>%
  mutate(p=ifelse(present==0,0,max_p))%>%
  group_by(p, hide_proportion)%>%
  mutate(correlation_with_target_letter_corrected = 
           correlation_with_target_letter-mean(correlation_with_target_letter, na.rm=T),
         occlusion=factor(ifelse(hide_proportion<0.2,'low','high')))

E2a.frames_df <- read_csv('../experiments/Exp2rowsLong/data/json_data/all_data.csv') %>%
  mutate(subj_id=PROLIFIC_PID,
         correct = as.numeric(correct),
         RT = as.numeric(RT),
         present=as.numeric(present),
         resp = response==presence_key,
         trial_index=subject_identifier+trial_index)%>%
  filter(test_part %in% c('test1','test2'))%>%
  mutate(p=ifelse(present==0,0,max_p))%>%
  group_by(p, hide_proportion)%>%
  mutate(correlation_with_target_letter_corrected = 
           correlation_with_target_letter-mean(correlation_with_target_letter, na.rm=T),
         occlusion=factor(ifelse(hide_proportion<0.2,'low','high')))

E1.rc_RT <- E1.frames_df %>%
  filter(frame_index<6 & correct)%>%
  group_by(subj_id,trial_index,present,occlusion)%>%
  summarise(evidence=mean(correlation_with_target_letter_corrected),
            RT=mean(RT))%>%
  group_by(subj_id,present,occlusion) %>%
  summarise(RT=cor(evidence,RT,method='spearman')) %>%
  group_by(subj_id,present)%>%
  summarise(RT=mean(RT))%>%
  spread(present,RT,sep='') %>%
  mutate(diff=present1+present0)

E1.rc_RT_mask <- E1.frames_df %>%
  filter(frame_index==1 & correct)%>%
  group_by(subj_id,trial_index,present,occlusion)%>%
  mutate(evidence=correlation_with_mask)%>%
  group_by(subj_id,present,occlusion) %>%
  summarise(RT=cor(evidence,RT,method='spearman')) %>%
  group_by(subj_id,present)%>%
  summarise(RT=mean(RT))%>%
  spread(present,RT,sep='') %>%
  mutate(diff=present1+present0)

E2.rc_RT <- E2.frames_df %>%
  filter(frame_index>7 & frame_index<13 & correct)%>%
  group_by(subj_id,trial_index,present,occlusion)%>%
  summarise(evidence=mean(correlation_with_target_letter_corrected),
            RT=mean(RT))%>%
  group_by(subj_id,present,occlusion) %>%
  summarise(RT=cor(evidence,RT,method='spearman')) %>%
  group_by(subj_id,present)%>%
  summarise(RT=mean(RT))%>%
  spread(present,RT,sep='') %>%
  mutate(diff=present1+present0)

E3.rc_RT <- E3.frames_df %>%
  filter(frame_index>7 & frame_index<13 & correct)%>%
  group_by(subj_id,trial_index,present,occlusion)%>%
  summarise(evidence=mean(correlation_with_target_letter_corrected),
            RT=mean(RT))%>%
  group_by(subj_id,present,occlusion) %>%
  summarise(RT=cor(evidence,RT,method='spearman')) %>%
  group_by(subj_id,present)%>%
  summarise(RT=mean(RT))%>%
  spread(present,RT,sep='') %>%
  mutate(diff=present1+present0)

E2a.rc_RT <- E2a.frames_df %>%
  filter(frame_index>7 & frame_index<13 & correct)%>%
  group_by(subj_id,trial_index,present,occlusion)%>%
  summarise(evidence=mean(correlation_with_target_letter_corrected),
            RT=mean(RT))%>%
  group_by(subj_id,present,occlusion) %>%
  summarise(RT=cor(evidence,RT,method='spearman')) %>%
  group_by(subj_id,present)%>%
  summarise(RT=mean(RT))%>%
  spread(present,RT,sep='') %>%
  mutate(diff=present1+present0)
 
```

<!-- We next asked whether random variation in the similarity of the stimulus to the target letter affected decision times, separately for decisions about presence and absence.  -->

(ref:RC) Reverse correlation analysis. A) Analysis approach. For each frame, the correlation between the demeaned noise and the target served as an index of stimulus-target similarity. We then extracted, for each frame number and participant, the correlation between these similarity measures and their corresponding trial-wise reaction times. This was done separately for correct target-present and target-absent decisions. B) mean correlations between RT and stimulus-target similarity across all participants. Error margins are 1 standard error from the mean. Statistical tests were performed on the mean over the first 300 ms of the stimulus. Grayscale images represent, for each individual pixel, the mean correlation between luminance over the first 300 ms and decision times (darker colors represent a negative correlation). Within each panel, decision kernels for target-absent decisions are presented above decision kernels for target-present decisions. For presentation purposes, we applied a Gaussian filter to the images (sigma=1), and present the contours of the target letters overlaid on top. \*\*\*: p\<0.001

```{r RC, echo=FALSE, fig.cap="(ref:RC)", out.width = '75%'}
knitr::include_graphics("figures/RC/RC.png")
```

As expected, higher levels of stimulus-target similarity made participants quicker to detect the target letter when it was present, and this was the case in all experiments (a one sample t-test on within-subject correlation coefficients, extracted separately for the two occlusion levels and then averaged per participant, Exp. 1, occluded pixels: `r apa_print(E1.rc_RT$present1%>%t.test())$statistic`; Exp. 2, occluded rows: `r apa_print(E2.rc_RT$present1%>%t.test())$statistic`; Exp. 3, occluded rows + reference: `r apa_print(E3.rc_RT$present1%>%t.test())$statistic`; blue curves in Fig. \@ref(fig:RC)B). In contrast, higher levels of stimulus-target similarity made participants slower to notice the absence of the letter when it was absent only in Exp. 1 (`r apa_print(E1.rc_RT$present0%>%t.test())$statistic`), but not in Exp. 2 (`r apa_print(E2.rc_RT$present0%>%t.test())$statistic`) and Exp. 3 (`r apa_print(E3.rc_RT$present0%>%t.test())$statistic`)). In all cases, the effect of stimulus-target similarity on decision times was stronger in target-present compared to target-absent responses (Exp. 1: `r apa_print(E1.rc_RT$diff%>%t.test())$statistic`, Exp. 2: `r apa_print(E2.rc_RT$diff%>%t.test())$statistic`, Exp. 3: `r apa_print(E3.rc_RT$diff%>%t.test())$statistic`; red curves in Fig. \@ref(fig:RC)). Together, while stimuli that were particularly S-like (or A-like) sped up the detection of the letter in all experiments, only in Exp. 1 we find evidence for the opposite pattern, where stimuli that were particularly unlike the target letter sped up decisions about the absence of a letter.

Confidence ratings in Exp. 2 further allowed us to test the relationship between stimulus-target similarity and subjective confidence, revealing a similar pattern. Confidence judgments in hits were positively correlated with stimulus-target similarity in the first 300 ms of the trial (`r E2.rc_confidence$present1%>%t.test()%>%apa_print()%>%'$'(statistic)`). In contrast, confidence in correct identifications of target absence showed no negative relationship to perceptual evidence (`r E2.rc_confidence$present0%>%t.test()%>%apa_print()%>%'$'(statistic)`). Similar to reaction times, the difference between the effect of perceptual evidence on confidence in presence and the (negative) effect of perceptual evidence on confidence in absence was in itself significant (`r E2.rc_confidence$diff%>%t.test()%>%apa_print()%>%'$'(statistic)`). Unlike confidence in presence, confidence in absence was not based on dissimilarity to the target letter. We return to this point in the General Discussion when discussing possible mechanisms of absence perception.

## Additional data collection: revealing individual differences

The absence of a group-level effect of occlusion on response times in target-absent trials may mean that individuals set their decision boundary, or the time they are willing to spend accumulating evidence before giving up and making a 'no' response, irrespective of expected stimulus visibility. Alternatively, this group null result may indicate that different participants are affected by counterfactual visibility in different ways. For example, some participants may decide to accumulate perceptual evidence for longer when more of the stimulus is occluded, expecting a target to take longer to be detected when it is there, whereas other participants may decide to quit early when more of the stimulus is occluded, reasoning that the expected rate of evidence accumulation is too low to warrant the extra time.

To arbitrate between the two possibilities we made use of a non-parametric test of within-subject effect reliability [@yaron2023individual]. The *sign-consistency test* is used to determine how consistent an individual's responses are across different trials. It does this by randomly splitting their trials into two subsets, and then checking whether both subsets demonstrate the same type of outcome: either positive or negative (see Fig. \@ref(fig:sc-results)A). In our case here, we measured the proportion of random splits for which both subsets show the same qualitative effect of stimulus occlusion on reaction times, separately in target-present and target-absent responses. The measure of sign-consistency is the proportion of these random splits where the same outcome is observed in both subsets. The mean sign consistency is then compared against a bootstrapped null distribution, to obtain a group-level p-value. Critically, unlike a standard t-test, sign-consistency can be high and significant even if positive and negative effects balance out at the group level, as long as single individuals are consistent within themselves.

Since the power of the sign-consistency test is affected much more by the number of trials per participant than by the number of participants [@yaron2023individual, appendix B], we decided to collect 896 trials from a subset of participants who took part in Exp. 2 and 3 (see Fig. \@ref(fig:sc-results)B). We contacted all participants who had accuracy of 70% or higher, and did not require more than one iteration over the instructions before passing the comprehension check. The first 10 participants from each study to accept our invitation were invited to take part in 5 20-minute experiments, which they could complete in their own free time. Over the course of these sessions we collected 896 trials per participant, with the exception of two participants in Exp. 3 for which we have 672 and 864 trials.

(ref:sc-results) A) An illustration of the sign-consistency test, for a hypothetical participant. Sign consistency is the proportion of random splits, out of 500, for which both trial subsets show the same qualitative effect. Individual sign-consistency scores are then averaged and compared against a non-parametric null-distribution to obtain a p-value. B) Occlusion effect distributions in Exp. 2 and 3. In order to obtain sufficient statistical power, we collected hundreds of trials from a random subset of 10 participants (marked with vertical lines). C) Sign consistency results. Within each panel, we present median RT as a function of occlusion level for each participant on the left. Color saturation indicates sign-consistency. On the right, we present individual sign-consistency scores as circles, alongside the group-average sign consistency score (horizontal line), overlaid on top of the non-parametric null distribution. In both experiments, group-level sign-consistency was significantly above chance for the effect of occlusion on response-time in target-absent trials. \*: p\<0.05, \*\*: p\<0.01, \*\*\*: p\<0.001

```{r sc-results, echo=FALSE, fig.cap="(ref:sc-results)"}
knitr::include_graphics("figures/occlusionSC.png")
```

```{r sc, message=F, warning=F, echo=F, include=F}

set.seed(1)

E2a.tp.directional <- E2a.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000) %>%
  filter(present==1 & correct==1) %>%
  dplyr::select(subj_id,hide_proportion,RT) %>%
  drop_na()%>%
  signcon::test_directional_effect(idv='subj_id',dv='RT',iv='hide_proportion', summary_function = median)

E2a.ta.directional <- E2a.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000) %>%
  filter(present==0 & correct==1) %>%
  dplyr::select(subj_id,hide_proportion,RT) %>%
  drop_na()%>%
  signcon::test_directional_effect(idv='subj_id',dv='RT',iv='hide_proportion', summary_function = median)

E2a.tp.sign_consistency <- E2a.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000) %>%
  filter(present==1 & correct==1) %>%
  dplyr::select(subj_id,hide_proportion,RT) %>%
  drop_na()%>%
  signcon::test_sign_consistency(idv='subj_id',dv='RT',iv='hide_proportion', 
                                 summary_function = median, perm_repetitions = 100)

E2a.ta.sign_consistency <- E2a.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000) %>%
  filter(present==0 & correct==1) %>%
  dplyr::select(subj_id,hide_proportion,RT) %>%
  drop_na()%>%
  signcon::test_sign_consistency(idv='subj_id',dv='RT',iv='hide_proportion', 
                                 summary_function = median, perm_repetitions = 100)


set.seed(1)

E3a.tp.directional <- E3a.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000) %>%
  filter(present==1 & correct==1) %>%
  dplyr::select(subj_id,hide_proportion,RT) %>%
  drop_na()%>%
  signcon::test_directional_effect(idv='subj_id',dv='RT',iv='hide_proportion', summary_function = median)

E3a.ta.directional <- E3a.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000) %>%
  filter(present==0 & correct==1) %>%
  dplyr::select(subj_id,hide_proportion,RT) %>%
  drop_na()%>%
  signcon::test_directional_effect(idv='subj_id',dv='RT',iv='hide_proportion', summary_function = median)

E3a.tp.sign_consistency <- E3a.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000) %>%
  filter(present==1 & correct==1) %>%
  dplyr::select(subj_id,hide_proportion,RT) %>%
  drop_na()%>%
  signcon::test_sign_consistency(idv='subj_id',dv='RT',iv='hide_proportion', 
                                 summary_function = median, perm_repetitions = 100)

E3a.ta.sign_consistency <- E3a.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & RT<5000) %>%
  filter(present==0 & correct==1) %>%
  dplyr::select(subj_id,hide_proportion,RT) %>%
  drop_na()%>%
  signcon::test_sign_consistency(idv='subj_id',dv='RT',iv='hide_proportion', 
                                 summary_function = median, perm_repetitions = 100)
```

Strikingly, in both experiments we find clear evidence for above-chance sign-consistency in the effects of occlusion on reaction times in target-absent trials (Exp. 2: sign consistency=`r printnum(E2a.ta.sign_consistency$statistic)`, $p$`r apa_p(E2a.ta.sign_consistency$p,add_equals=T)`; Exp. 3: sign consistency=`r printnum(E3a.ta.sign_consistency$statistic)`, $p$`r apa_p(E3a.ta.sign_consistency$p,add_equals=T)`; see Fig. \@ref(fig:sc-results)C). Moreover, target-absent sign-consistency scores were not significantly different from, and numerically higher than, target-present sign-consistency scores (Exp. 2: sign consistency=`r printnum(E2a.tp.sign_consistency$statistic)`, $p$`r apa_p(E2a.tp.sign_consistency$p,add_equals=T)`; Exp. 3: sign consistency=`r printnum(E3a.tp.sign_consistency$statistic)`, $p$`r apa_p(E3a.tp.sign_consistency$p,add_equals=T)`). An effect of counterfactual visibility on target-absent response times was not absent, it was masked by qualitative differences between individual participants. Specifically, for some participants, occlusion had opposite effects on the timing of decisions about presence and absence, slowing down decisions about presence, but speeding up decisions about absence.

# Discussion

Occlusion affects not only the visibility of objects, but also the counterfactual visibility of absent objects: how visible they would have been had they been present. Here, to pinpoint the roles of counterfactual visibility in perceptual decision making, we asked whether occlusion had similar effects on perceiving stimuli and their absence. We find that decisions about presence and absence alike are more susceptible to errors, and are made with lower levels of confidence, when more of the display is occluded. When it comes to decision times, however, the effects of occlusion changes as a function of target presence: a group-level slowing-down for more occluded targets versus reliable heterogeneity in effects signs (speeding up in some participants, slowing down in other participants) for the effects of occlusion when a target is absent.

Effects of stimulus occlusion on detection specificity and confidence in absence indicate that absence was inferred not only on the basis of failing to see the target. On target-absent trials, letter targets were similarly absent when occluded by two or six rows of black pixels. Had participants been basing their decisions only on not seeing the target, or on the mismatch between their sensory expectations for presence and the visual input [@farennikova2013; @farennikova2015], their false-alarm rates and confidence ratings would have been unaffected by different levels of absence occlusion, in contrast to what we find here.

Still, these results are consistent with two underlying mechanisms. First, participants may have incorporated expectations about counterfactual visibility into their criterion setting and confidence judgments, and second, participants may have inferred stimulus absence not based on their failure to see a letter, but based on their ability to directly perceive the absence of a letter. If absence can be directly perceived, rather than inferred, occluding more of the absence should make it more difficult to see, bringing down decision specificity and confidence.

Reverse correlation analysis provides some support for the perception of absence in the stimulus itself in Exp. 1, where participants made quicker decisions about absence when random noise in the display was negatively correlated with the target letter. However, this pattern was not observed in Exp. 2 and 3 (nor in the long version of Exp. 2; `r apa_print(E2a.rc_RT$present0%>%t.test())$statistic`), and in all four experiments the effect was weaker than in target-present trials (long version of Exp. 2: `r apa_print(E2a.rc_RT$diff%>%t.test())$statistic`). Furthermore, stimulus-target similarity affected decision confidence only when the target was present, despite a robust effect of partial occlusion on decision confidence in both target-present and target-absent trials. It seems that, to the extent that salient mismatches between the presented stimulus and the expected target contributed to decisions about absence, this effect was weaker than the positive effect of target-matching stimuli on decisions about presence.

In the case of confidence ratings, reverse correlation provides a more definite answer: while confidence in absence was sensitive to the level of occlusion, it was not sensitive to the revealed content of the display behind the occluders. At the metacognitive level, confidence in absence is driven by counterfactual visibility over and above any direct perception of missing objects.

Critically, despite some evidence for stimulus-target similarity driving reaction times in decisions about absence in Exp. 1, a careful look at reaction time data is still most consistent with the incorporation of counterfactual visibility into detection decisions over and above such effects. First, participants were considerably slower to report target absence, with median differences of around 350 ms between target-present and target-absent response times in all three experiments. This is consistent with decisions about absence being made only once participants are certain that they "would have detected the target by now" [@mazor2021]. Moreover, sign-consistency analysis revealed a significant subset of participants for whom partial occlusion had opposite effects on target-present and target-absent decision times, slowing down target-present responses but speeding up target-absent responses. If occluders blocked visual access to the absence of a target, responses would have been slowed down by the occlusion of targets and target-absences alike.

This divergent pattern in response times can be accounted for, however, if subjects make decisions about absence when presence has not been perceived and the potential for gaining more information by waiting for longer is too small to justify the additional time. In such a model, the timing of decisions about presence is a function of the gradual increase in perceptual evidence in time, which is both slower and plateaus at a lower level of visibility when more of the display is occluded. Decisions about absence, in contrast, are dependent on two other quantities: first, subjects' expectations regarding how much evidence they should expect to accumulate as a function of time when a target is present, and second, the subjective cost of waiting. Inter-individual differences in the first quantity can account for this heterogeneity in the timing of inferences about absence (see Appendix). Critically, this model is consistent with a blanket decrease in specificity and confidence when more of the display is occluded, as subjects know they are more likely to miss targets then.

Our results fit within the broader project of understanding perception as probabilistic inference on noisy sensory data. Much focus has been placed on the role of prior expectations in perceptual inference [@summerfield2009; @kok2013; @yon2020action; @press2020], with important discussions regarding the (im)penetrability of visual perception to such effects from cognition [@pylyshyn1999; @firestone2016]. Here we focus on the other component of Bayesian reasoning, often neglected in such discussions: the likelihood function going from world states to sensory input. Unlike prior expectations about the world (e.g., the probability that a letter will be present in the next trial), these likelihood functions describe the perceptual system itself (e.g., the probability that I would be able to perceive the letter when it is present). As we show here, such beliefs affect not only metacognitive confidence ratings, but also decision times and decision criteria of the detection judgments themselves, revealing a complex web of interactions between perception, cognition, and metacognition.

Overall, analysis of decision criteria, reaction times and decision confidence, followed by a more focused examination of individual differences, indicate that humans take into account beliefs about counterfactual visibility when making perceptual detection judgments, and when judging their subjective confidence in such decisions. This is consistent with perception as "inverse optics": the inference of latent external causes based on noisy sensory data [@alhazen2001; @helmholtz1866; @friston2010; @gershman2012]. For such inference to be rational, not only the available evidence has to be considered, but also the evidence that would have been available had things been different. Indeed, outside perception, reasoning about counterfactual allows humans infer causal links between events [@gerstenberg2021] and optimize their behavioural policies to maximize reward [@palminteri2017 ; @boorman2009]. Here we show that a similar principle is at play within perception. We perceive absence when we believe presence would have been visible.

# Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. Experiments 1, 2, and 3 correspond to Experiments 3, 4, and 6 of a project looking at the effects of different manipulations on inference about absence. Experiments 1, 2, and 5 used a context manipulation, and will be reported separately.

## Participants

The research complied with all relevant ethical regulations, and was approved by the Research Ethics Committee of Birkbeck, University of London (study ID number 1812000). In all experiments, participants were recruited via Prolific, and gave informed consent prior to their participation. To be eligible to take part, their Prolific approval rate had to be 95% or higher, their reported first language English, and their age between 18 and 60. Our pre-registered plan was to collect data until we reach 250, 210 and 250 participants for Exp. 1, 2, and 3, respectively. Due to an error in the pre-processing script, we ended up collecting data from `r E2.df$subj_id%>%unique()%>%length()` included participants (after applying our pre-registered exclusion criteria) in Exp. 2. We decided to keep the additional participants, noting that their inclusion does not change the pattern of the results. The experiments took about 12 minutes to complete, and participants were paid according to an hourly wage of £7.50.

## Procedure

Participants detected the presence or absence of a target letter (S or A, in different blocks) in a patch of dynamic grayscale noise presented at 15 frames per second. In each frame, noise was generated by randomly sampling grayscale values from a target image $I$. Specifically, for each pixel $S_{ij}$, we displayed the grayscale value for the corresponding pixel in the original, noise-free, image $I_{ij}$ with some probability $p$, and the grayscale value of a randomly chosen pixel $I_{i'j'}$ (sampled with replacement) with probability $1-p$. On target-absent trials, $p$ was set to $0$, such that grayscale values of all pixels were randomly shuffled, with replacement. On target-present trials, the probability $p$ was set to a positive number between 0 and 1. In Exp. 1 and 2, $p$ was calibrated online to achieve performance levels of around 80%, following a 1-up-3-down procedure, starting at $v=0.35$ and following a multiplicative set size of $0.9$, which moved closer to 1 following each change direction in the calibration process. In Exp. 3, $p$ was set to 0.3 throughout the entire experiment. Responses were delivered using the F and G keyboard keys (counterbalancing response mapping across subjects).

After reading the instructions, participants completed four practice trials. In case their accuracy in these four practice trials fell below 3/4, they were reminded of task instructions and given additional practice trials, until reaching the desired accuracy level. Otherwise, they continued to the main part of the experiment. Here, their task was exactly the same, but the noise patch was partly occluded. In Exp. 1, occluders were randomly positioned static black pixels, which covered 5% or 15% of the stimulus on different trials. In Exp. 2 and 3, occluders were randomly positioned rows of black pixels (2 or 6 rows, on different trials) which extended beyond the stimulus. In order to make clear that the occluders are not part of the main stimulus, occluder rows in Exp. 2 and 3 preceded the main stimulus by 500 ms. Finally, in Exp. 3, two similar "reference" stimuli were presented on both sides of the central stimulus. In these reference stimuli, the target letter was always presented with $p=0.3$ regardless of the presence of a letter in the central stimulus. Participants were explained that they should respond based on the central stimulus only, and continued to the main part of the experiment only once they had passed a comprehension check.

The main part of the experiment comprised four blocks of 16 trials. For approximately half of the participants, in blocks 1 and 2 the target letter was S and in blocks 3 and 4 it was A. The order of letters was reversed for the other half. In blocks 3 and 4 of Exp. 2, participants used their mouse to rate their confidence on a vertical analog scale immediately after deciding whether the letter was present or absent. To move on to the third block, participants had to respond correctly on at least 3 out of 4 trials, and to correctly answer a multiple-option comprehension question about the use of the confidence scale.

```{r subjective-reports}
E2.subjective <- E2.df %>% filter(substr(response,3,18)=='which_was_harder') %>% group_by(response)%>%summarise(n=n()) %>%
    mutate(response = case_when(
        str_detect(response, fixed("No!")) ~ "no",
        str_detect(response, "more") ~ "more",
        str_detect(response, "less") ~ "less",
        TRUE ~ response
    ))%>%spread(response,n)
```

Finally, at the end of Exp. 2, participants were asked to report whether occlusion affected how difficult it was to detect the letter. `r E2.subjective$more` participants reported that occluding more of the stimulus made detecting the target letter harder, `r E2.subjective$less` reported it made detecting the target letter easier, and the remaining `r E2.subjective$no` reported it had no effect on difficulty.

\newpage

# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```
