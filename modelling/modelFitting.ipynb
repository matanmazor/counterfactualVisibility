{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "36a8ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.stats import gamma as gamma_dist\n",
    "from scipy.stats import norm\n",
    "from scipy.signal import convolve\n",
    "import random\n",
    "from os import path as path\n",
    "import time\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8eb6be",
   "metadata": {},
   "source": [
    "For each combination of parameters, the function returns an array of size $2\\times2\\times T$.\n",
    "\n",
    "* The first dimension is target presence (0 or 1)\n",
    "* The second is response (0 or 1)\n",
    "* the third is RT (in units of time points).\n",
    "\n",
    "Entries are probabilities. The sum of the array is set to 2: that is, probabilities are conditional on target presence/absence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "83c35d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(true_thetas, believed_thetas, gamma, shape, scale, T):\n",
    "    \n",
    "    # true thetas:  [p(1|absent), p(1|present)]\n",
    "    # believed thetas: participants beliefs about the true thetas\n",
    "    # gamma: the temporal discount factor\n",
    "    # T number of time points to simulate\n",
    "    # shape and scale: parameters of the gamma distribution for non-decision times. \n",
    "    \n",
    "    #1. FIND POLICY\n",
    "    \n",
    "    # V is value. We simulate T*2 time here so that we can use the first T to get the threshold.\n",
    "    V=np.full([T*2+1, T*2+1],np.nan);\n",
    "\n",
    "    # A is action\n",
    "    A=np.full([T*2+1, T*2+1],np.nan);\n",
    "\n",
    "    # LLR is LLR\n",
    "    LLR=np.full([T*2+1, T*2+1],np.nan);\n",
    "    \n",
    "    # Backward induction!\n",
    "    for t in range(T*2, -1, -1):\n",
    "        states= np.array(range(t+1)); # the state is the number of 1's observed so far\n",
    "        LLR_at_t= states*(np.log(believed_thetas[1])- np.log(believed_thetas[0])) + \\\n",
    "        (t-states)*(np.log(1-believed_thetas[1])- np.log(1-believed_thetas[0]));\n",
    "        \n",
    "        LLR[t,states]= LLR_at_t;\n",
    "        \n",
    "        #to avoid overflow errors later. \n",
    "        clipped_LLR_at_t = np.clip(LLR_at_t,-500,500)\n",
    "\n",
    "        P_present= np.exp(clipped_LLR_at_t)/(1+np.exp(clipped_LLR_at_t));\n",
    "        \n",
    "        # the expected value if I make a decision now is the probability of being correct\n",
    "        V_choose_now= np.maximum(P_present,1-P_present)\n",
    "        \n",
    "        # We start by assuming that the agent makes a decision at the last time point, and move backward from there.\n",
    "        if t==T*2:\n",
    "            V[t, states]= V_choose_now;\n",
    "            # I code 'target-present' decisions as 1, 'target-absent' decisions as 0, and waiting as np.nan\n",
    "            A[t,states]= np.where(LLR_at_t>0,1,0);\n",
    "            \n",
    "        else:\n",
    "            # Calculate value if waiting\n",
    "            # the probability of obtaining a 1, marginalized over target presence and absence\n",
    "            prob1= P_present*believed_thetas[1]+ (1-P_present)*believed_thetas[0];\n",
    "            # the expected value if I wait is gamma times the expected value in the next time point.\n",
    "            V_wait= gamma*(prob1*V[t+1,states+1]+ (1-prob1)*V[t+1,states]);\n",
    "            \n",
    "            # the expected value is the maximum between the expected value if I wait or if I make a decision.\n",
    "            V[t,states] = np.maximum(V_choose_now,V_wait)\n",
    "            \n",
    "            A[t,states] = np.where(V_choose_now>V_wait,1,np.nan) * np.where(LLR_at_t>0,1,0)\n",
    "        \n",
    "    # 2. RUN SIMULATION FORWARD\n",
    "    model_predictions = np.full([2,2,T],0.0);\n",
    "\n",
    "    # run target absence trials\n",
    "    prob=np.full([T+1, T+1],0.0);\n",
    "    prob[0,0]=1\n",
    "    for t in np.arange(0,T):\n",
    "        for state in np.arange(0,t+1):\n",
    "            if prob[t,state]==0:\n",
    "                continue\n",
    "            else:\n",
    "                if not np.isnan(A[t,state]):\n",
    "                    decision= int(A[t,state])\n",
    "                    model_predictions[0,decision,t] = prob[t,state]\n",
    "                else:\n",
    "                    prob[t+1,state] += prob[t,state]*(1-true_thetas[0])\n",
    "                    prob[t+1,state+1] += prob[t,state]*true_thetas[0]\n",
    "                    \n",
    "    # run target presence trials\n",
    "    prob=np.full([T+1, T+1],0.0);\n",
    "    prob[0,0]=1\n",
    "    for t in np.arange(0,T):\n",
    "        for state in np.arange(0,t+1):\n",
    "            if prob[t,state]==0:\n",
    "                continue\n",
    "            else:\n",
    "                if not np.isnan(A[t,state]):\n",
    "                    decision= int(A[t,state])\n",
    "                    model_predictions[1,decision,t] = prob[t,state]\n",
    "                else:\n",
    "                    prob[t+1,state] += prob[t,state]*(1-true_thetas[1])\n",
    "                    prob[t+1,state+1] += prob[t,state]*true_thetas[1]\n",
    "   \n",
    "    if model_predictions.sum()<1.95:\n",
    "       raise ValueError(\"increase T, a non-negligible number of trials is beyond the scope of the simulation\")\n",
    "    \n",
    "    # Convolve with gamma\n",
    "    gamma_pdf = gamma_dist.pdf(np.linspace(0, 100, 100), a=shape, scale=scale)\n",
    "    gamma_pdf /= sum(gamma_pdf)\n",
    "    \n",
    "    # Prepare to store or plot the convolved data\n",
    "    convolved_model_predictions = np.zeros_like(model_predictions)\n",
    "\n",
    "    # Iterate over each combination in the first two dimensions and perform convolution\n",
    "    for present in range(2):\n",
    "        for response in range(2):\n",
    "            # Convolve the gamma distribution with the current 1D slice\n",
    "            # Using 'same' mode to ensure the output size matches the input\n",
    "            convolved_model_predictions[present, response, :] = \\\n",
    "            convolve(model_predictions[present, response, :], gamma_pdf)[:model_predictions.shape[2]]+0.00001\n",
    "\n",
    "    \n",
    "    convolved_model_predictions[0, :, :] /= np.sum(convolved_model_predictions[0, :, :])\n",
    "    convolved_model_predictions[1, :, :] /= np.sum(convolved_model_predictions[1, :, :])\n",
    "    \n",
    "    return(convolved_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions_ndt(true_thetas, believed_thetas, gamma, ndt, T):\n",
    "    \n",
    "    # true thetas:  [p(1|absent), p(1|present)]\n",
    "    # believed thetas: participants beliefs about the true thetas\n",
    "    # gamma: the temporal discount factor\n",
    "    # T number of time points to simulate\n",
    "    # non-decision time: non-decision time, in time-points \n",
    "    \n",
    "    #1. FIND POLICY\n",
    "    \n",
    "    # V is value. We simulate T*2 time here so that we can use the first T to get the threshold.\n",
    "    V=np.full([T*2+1, T*2+1],np.nan);\n",
    "\n",
    "    # A is action\n",
    "    A=np.full([T*2+1, T*2+1],np.nan);\n",
    "\n",
    "    # LLR is LLR\n",
    "    LLR=np.full([T*2+1, T*2+1],np.nan);\n",
    "    \n",
    "    # Backward induction!\n",
    "    for t in range(T*2, -1, -1):\n",
    "        states= np.array(range(t+1)); # the state is the number of 1's observed so far\n",
    "        LLR_at_t= states*(np.log(believed_thetas[1])- np.log(believed_thetas[0])) + \\\n",
    "        (t-states)*(np.log(1-believed_thetas[1])- np.log(1-believed_thetas[0]));\n",
    "        \n",
    "        LLR[t,states]= LLR_at_t;\n",
    "        \n",
    "        #to avoid overflow errors later. \n",
    "        clipped_LLR_at_t = np.clip(LLR_at_t,-500,500)\n",
    "\n",
    "        P_present= np.exp(clipped_LLR_at_t)/(1+np.exp(clipped_LLR_at_t));\n",
    "        \n",
    "        # the expected value if I make a decision now is the probability of being correct\n",
    "        V_choose_now= np.maximum(P_present,1-P_present)\n",
    "        \n",
    "        # We start by assuming that the agent makes a decision at the last time point, and move backward from there.\n",
    "        if t==T*2:\n",
    "            V[t, states]= V_choose_now;\n",
    "            # I code 'target-present' decisions as 1, 'target-absent' decisions as 0, and waiting as np.nan\n",
    "            A[t,states]= np.where(LLR_at_t>0,1,0);\n",
    "            \n",
    "        else:\n",
    "            # Calculate value if waiting\n",
    "            # the probability of obtaining a 1, marginalized over target presence and absence\n",
    "            prob1= P_present*believed_thetas[1]+ (1-P_present)*believed_thetas[0];\n",
    "            # the expected value if I wait is gamma times the expected value in the next time point.\n",
    "            V_wait= gamma*(prob1*V[t+1,states+1]+ (1-prob1)*V[t+1,states]);\n",
    "            \n",
    "            # the expected value is the maximum between the expected value if I wait or if I make a decision.\n",
    "            V[t,states] = np.maximum(V_choose_now,V_wait)\n",
    "            \n",
    "            A[t,states] = np.where(V_choose_now>V_wait,1,np.nan) * np.where(LLR_at_t>0,1,0)\n",
    "        \n",
    "    # 2. RUN SIMULATION FORWARD\n",
    "    model_predictions = np.full([2,2,T+ndt],0.0);\n",
    "\n",
    "    # run target absence trials\n",
    "    prob=np.full([T+1, T+1],0.0);\n",
    "    prob[0,0]=1\n",
    "    for t in np.arange(0,T):\n",
    "        for state in np.arange(0,t+1):\n",
    "            if prob[t,state]==0:\n",
    "                continue\n",
    "            else:\n",
    "                if not np.isnan(A[t,state]):\n",
    "                    decision= int(A[t,state])\n",
    "                    model_predictions[0,decision,t+ndt] = prob[t,state]\n",
    "                else:\n",
    "                    prob[t+1,state] += prob[t,state]*(1-true_thetas[0])\n",
    "                    prob[t+1,state+1] += prob[t,state]*true_thetas[0]\n",
    "                    \n",
    "    # run target presence trials\n",
    "    prob=np.full([T+1, T+1],0.0);\n",
    "    prob[0,0]=1\n",
    "    for t in np.arange(0,T):\n",
    "        for state in np.arange(0,t+1):\n",
    "            if prob[t,state]==0:\n",
    "                continue\n",
    "            else:\n",
    "                if not np.isnan(A[t,state]):\n",
    "                    decision= int(A[t,state])\n",
    "                    model_predictions[1,decision,t+ndt] = prob[t,state]\n",
    "                else:\n",
    "                    prob[t+1,state] += prob[t,state]*(1-true_thetas[1])\n",
    "                    prob[t+1,state+1] += prob[t,state]*true_thetas[1]\n",
    "   \n",
    "    if model_predictions.sum()<1.95:\n",
    "       raise ValueError(\"increase T, a non-negligible number of trials is beyond the scope of the simulation\")\n",
    "    \n",
    "    model_predictions=model_predictions[:,:,:T]\n",
    "    \n",
    "    # Convolve with normal\n",
    "    normal_pdf = norm.pdf(np.linspace(-50, 50, 100), loc=0, scale=1)\n",
    "    normal_pdf /= sum(normal_pdf)\n",
    "    \n",
    "    # Prepare to store or plot the convolved data\n",
    "    convolved_model_predictions = np.zeros_like(model_predictions)\n",
    "\n",
    "    # Iterate over each combination in the first two dimensions and perform convolution\n",
    "    for present in range(2):\n",
    "        for response in range(2):\n",
    "            # Convolve the gamma distribution with the current 1D slice\n",
    "            # Using 'same' mode to ensure the output size matches the input\n",
    "            convolved_model_predictions[present, response, :] = \\\n",
    "            convolve(model_predictions[present, response, :], normal_pdf)[:model_predictions.shape[2]]+0.00001\n",
    "\n",
    "    \n",
    "    convolved_model_predictions[0, :, :] /= np.sum(convolved_model_predictions[0, :, :])\n",
    "    convolved_model_predictions[1, :, :] /= np.sum(convolved_model_predictions[1, :, :])\n",
    "    \n",
    "    return(convolved_model_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b274e",
   "metadata": {},
   "source": [
    "We need to fomat participants data in a way that is similar to convolved_model_predictions, but using counts instead of probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3a292df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=1000\n",
    "\n",
    "df = pd.read_csv(\"data/E2a.csv\") \n",
    "df['present'] = df['present'].replace(-1, 0)\n",
    "df['decision'] = (((df['correct'] == 1) & (df['present'] == 1)) | ((df['correct'] == 0) & (df['present'] == 0))).astype(int)\n",
    "df['rt'] = (df['rt'] / 0.05).round().astype(int)\n",
    "\n",
    "df_filtered = df[df['subj_id'] == 1]\n",
    "\n",
    "# Ensure all possible combinations are represented in the DataFrame, even those with zero counts\n",
    "categories = {\n",
    "    'present': [0, 1],\n",
    "    'decision': [0, 1],\n",
    "    'rt': range(T)\n",
    "}\n",
    "\n",
    "# Create a MultiIndex from the Cartesian product of the categories\n",
    "index = pd.MultiIndex.from_product(categories.values(), names=categories.keys())\n",
    "\n",
    "# Group by the necessary columns and count occurrences\n",
    "df_grouped = df_filtered.groupby(['present', 'decision', 'rt']).size().reindex(index, fill_value=0)\n",
    "\n",
    "# Unstack the MultiIndex DataFrame to create a 3D structure (2x2xT)\n",
    "df_unstacked = df_grouped.unstack(level=['present', 'decision'])\n",
    "\n",
    "subj1_data = df_unstacked.values.reshape((2, 2, len(categories['rt'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "205d7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=400\n",
    "\n",
    "def negative_likelihood(params, data, T):\n",
    "# params are in the order:\n",
    "# true_theta0, [0]\n",
    "# true theta1; [1]\n",
    "# believed theta0; [2]\n",
    "# believed theta1; [3]\n",
    "# gamma for temporal discounting; [4]\n",
    "# shape for gamma function; [5]\n",
    "# scale for gamma function; [6]\n",
    "# lapse rate; [7]\n",
    "    predictions = get_model_predictions(params[:2], params[2:4], params[4], params[5], params[6], T);\n",
    "    log_p = np.log(predictions)\n",
    "    \n",
    "    return(-np.sum(data*log_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "92a12e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params=[1,2,3,4,5,6,7,8,9,10]\n",
    "params[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7174a123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanzor\\AppData\\Local\\Temp/ipykernel_5428/2795680548.py:92: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma_pdf /= sum(gamma_pdf)\n"
     ]
    }
   ],
   "source": [
    "T=1000\n",
    "# negative_likelihood([0.1,0.3,0.05,0.25,0.999,2,1],subj1_data,T)\n",
    "initial_params = [0.15,0.2,0.15,0.2,0.99,1,1]\n",
    "result = minimize(negative_likelihood, initial_params, args=(subj1_data,T), \\\n",
    "                  bounds = [(0,1),(0,1),(0,1),(0,1),(0.5,0.999),(0.001,10), (0.001,10)], \\\n",
    "                  method='Nelder-Mead')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "15dd3853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           message: `gtol` termination condition is satisfied.\n",
       "           success: True\n",
       "            status: 1\n",
       "               fun: 9679.215668491654\n",
       "                 x: [ 2.230e-01  2.630e-01  2.230e-01  2.630e-01  9.373e-01\n",
       "                      1.526e+00  1.028e+00]\n",
       "               nit: 15\n",
       "              nfev: 40\n",
       "              njev: 5\n",
       "              nhev: 0\n",
       "          cg_niter: 16\n",
       "      cg_stop_cond: 0\n",
       "              grad: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
       "                      0.000e+00  0.000e+00]\n",
       "   lagrangian_grad: [-1.438e-09 -1.448e-09 -1.438e-09 -1.448e-09  5.299e-10\n",
       "                     -3.813e-09 -4.503e-09]\n",
       "            constr: [array([ 2.230e-01,  2.630e-01,  2.230e-01,  2.630e-01,\n",
       "                            9.373e-01,  1.526e+00,  1.028e+00])]\n",
       "               jac: [<7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                    \twith 7 stored elements in Compressed Sparse Row format>]\n",
       "       constr_nfev: [0]\n",
       "       constr_njev: [0]\n",
       "       constr_nhev: [0]\n",
       "                 v: [array([-1.438e-09, -1.448e-09, -1.438e-09, -1.448e-09,\n",
       "                            5.299e-10, -3.813e-09, -4.503e-09])]\n",
       "            method: tr_interior_point\n",
       "        optimality: 4.5033351886059345e-09\n",
       "  constr_violation: 0.0\n",
       "    execution_time: 5.254597187042236\n",
       "         tr_radius: 59907875.59295273\n",
       "    constr_penalty: 1.0\n",
       " barrier_parameter: 1.0240000000000006e-08\n",
       " barrier_tolerance: 1.0240000000000006e-08\n",
       "             niter: 15"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
